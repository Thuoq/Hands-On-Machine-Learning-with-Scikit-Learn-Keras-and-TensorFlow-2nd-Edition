{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.Introduction to ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcz6T4BylBlPeqBRw+k16E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thuoq/Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow-2nd-Edition/blob/main/10_Introduction_to_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z0UtDcWGEkj"
      },
      "source": [
        "## Building an Image Classifier Usign Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw9Box9XHWvE"
      },
      "source": [
        "#### Using Keras to load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z4BlgbxHloE",
        "outputId": "87fcb389-20bc-47d1-f588-75d373667cce"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqD3NE98IyTh"
      },
      "source": [
        "fashin_minst = keras.datasets.fashion_mnist\n",
        "(X_train_full,y_train_full),(X_test,y_test) = fashin_minst.load_data()\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTEIkmwLI58A"
      },
      "source": [
        "Khi chúng loading MNIST or Fasshion MNIST sử dung Keras thay vì Scikit-Learn, 1 điểm khác biệt ở đây là mỗi hình ảnh sẽ đại diện là 28x28 thay vì 1 array 784D. và pixel từ 0->255 thay vì float như scikit learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo6Bsa1oK69y",
        "outputId": "3a7f3415-56e7-40dd-da8a-085ea7047460"
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDHeDInZK8fs",
        "outputId": "5c577673-bc47-4ba4-a334-c11426b202c4"
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTNVoHd3K-Cu"
      },
      "source": [
        "Nhớ rằng vì tập dữ liệu là thường split into test_set và và training set, chúng ta cần tạo validation test. và chia cho 255.0 để chuyển sao float "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH9gmlXBLuPA"
      },
      "source": [
        "X_valid , X_train = X_train_full[:5000] / 255.0,X_train_full[5000:]/255.0\n",
        "y_valid, y_train = y_train_full[:5000],y_train_full[5000:]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_FkSvzRMIIu"
      },
      "source": [
        "Creating 1 class_name make the name of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9TaHD_N4RC"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P51ssSSeN4uj",
        "outputId": "3bec8f07-e937-47d9-8118-301c0eb3e489"
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMUI9QPUN72b"
      },
      "source": [
        "##### Creating the mode using Sequntial API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GF7bQXrOIFw"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMGaH0EhjPJ_"
      },
      "source": [
        "## From biological to Artificial Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUAmbp9sjlho"
      },
      "source": [
        "## The Multilayer Perceptron and Backpropagation\n",
        "**Định nghĩa**: An MLP là tổng hợp đi qua nhiều input layers, 1 hoặc nhiều TLU layers trong đó, finaly layers đc gọi input còn bên trong được gọi là hidden layers, và mỗi hidden layers đều có thêm thằng bias nữa, \n",
        "\n",
        "**Note**: Dòng tín hiệu từ input -> output chỉ 1 đường được gọi là  *Feedforward Neural Network*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAg1EseAkC_8"
      },
      "source": [
        "Định nghĩa: An MLP là tổng hợp đi qua nhiều input layers, 1 hoặc nhiều TLU layers  trong đó\n",
        "\n",
        "Đó là cái kiến trúc nhưng làm sao để được train nó.1986, đã giới thiệu **backpropagation** cách khác của Gradient , sử dụng kỹ thuật hiệu quả sử dụng một kỹ thuật hiệu quả để tính toán các gradient tự động\n",
        "\n",
        "Và có 1 điều họ thay đổi cái cách tính full connection bằng hàm logistic vì ntn mới sử dụng đc Gradient\n",
        "1. hyperbolic tangent\n",
        "2. Rectified Linear Unit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq2ann2hHRQx"
      },
      "source": [
        "### Regresion MLPs \n",
        "\n",
        "1. Input neurons - Oneper input features\n",
        "2. Hidden layers - Dựa trên problem, thường là 1 tới 5\n",
        "3. neurons per hidden layers - 10 -> 100\n",
        "4. Output is 1 perdiction dimention\n",
        "5. Hidden activation: ReLU\n",
        "6. Output activation thường thường là relu of softpluts , or logisc/tank\n",
        "7. loss fnc huber(nếu có ngoại lệ) MSE or MAEE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ41mu8cMEqk"
      },
      "source": [
        "### Classification MLPs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f02BwngMvUV"
      },
      "source": [
        "Khác regression ở 1 vài chỗ ví dụ\n",
        "\n",
        "1. Output layer activation Logistic\n",
        "2. Loss func là cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoGNY7KqVK2E"
      },
      "source": [
        "## Building an Image Classifier Using the Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI4vFRYjNk5i"
      },
      "source": [
        "#### Using Keras to load the dataset \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzcuN0DQO0DS"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full,y_train_full),(X_test,y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp48dWUmO51E"
      },
      "source": [
        "Khi loading MNIST hoặc Fashion MNIST sử dụng Keras thay vì Scikit-Learn, 1 cái sự khác biệt rằng tất cả các hình ảnh đại diện là 28x28 thay vì là 1 D arrat 784. Hơn nữa cái pixel đại diện từ 0->255 thay vì 0.0 -> 255.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMUDYMnqPemb",
        "outputId": "0d3fe7a9-375e-4b9a-efdb-5dc49006e305"
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QqfOzkZPfnP",
        "outputId": "ee433b35-5356-4c46-f517-a9a3bac0f317"
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ9eAUDUPjtS"
      },
      "source": [
        "Vì chúng ta chuẩn bị train với neural networrk sử dụng Gradient, chúng ta phải scal the input featues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT68OJDKQivD"
      },
      "source": [
        "X_valid,X_train = X_train_full[:5000]/255.0,X_train_full[5000:]/255.0\n",
        "y_valid,y_train = y_train_full[:5000],y_train_full[5000:]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMIf9wpiQz68"
      },
      "source": [
        "Chúng ta cần 1 list của các class names để biết cái gì chúng ta đang làm việc hay nói cách khác dể biết out put nó là cái gì \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4H6vfLNRYRa"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zHsBaVOrRa5Y",
        "outputId": "b68772f3-341d-4cd7-8f61-81cd770efc1c"
      },
      "source": [
        "class_names[y_train[0]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GZ1WyQ4RcDP"
      },
      "source": [
        "#### Creating the model using the Sequential API\n",
        "nào chúng ta cùng build 1 neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKVdjCVBRyjk"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300,activation='relu'))\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGXLHWQoSKPA"
      },
      "source": [
        "Nào chúng ta cùng sẽ cùng giải thích code ở trên line by line : \n",
        "1. Dòng đầu tiên chúng ta tạo 1 `Sequential` model. Đây là 1 loại của Keras model cho neural netwwork rằng chỉ bao gồm các lớp được xét tuần tự đó được gọi là. Sequential AP I\n",
        "2. Tiếp theo chúng ta xây dựng layerss đầu tiên và thêm nó vào model. Đó là `Flatten` layerss nó có vào trò chuyển các input image thành 1D array. Nếu nó nhận input data X, nó tính `X.reshape(-1.1)`\n",
        "Layer này không nâhnj 1 parameters nào , chúng ta nên chỉ đinh cái `input_shape`\n",
        "3. Tiếp theo chúng ta thêm Desen hidden layers với 300 nerons. Nó sẽ sử dụng `ReLu` activation fnc. Khi nó nhận ip data nó sẽ tính fully connected \n",
        "4. Cuối cùng, chúng ta thêm a Dense có output layers với 10 nerons. sử dugnj softmax activation (bởi vì chúng ta cần loai trừ )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcsIcNUDUYc9"
      },
      "source": [
        "`summary()` methods của moddel sẽ hiển thị ra model's layerss, bao gồm các loại tên lay'rss và những numerr của parametres của chúng . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QTA3XaeVmT2",
        "outputId": "2892c107-282d-4629-d637-c5d0ce1f700a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRBkF1zKWN1Z"
      },
      "source": [
        "Nhớ rằng chúng **Dense** layes thường có rất nhiều parametters. Ví dụ the first hidden layer có 784x300 connection + weight 3000 bias -> là ra 235,500. Điều này mang lại cho mô hình khá nhiều tính linh hoạt để phù hợp với dữ liệu đào tạo, nhưng nó cũng có nghĩa là mô hình có nguy cơ bị overfitting, đặc biệt là khi bạn không có nhiều dữ liệu đào tạo. Chúng ta sẽ quay lại vấn đề này sau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_FmH_6kWsYy"
      },
      "source": [
        "Tất cả các parameters của một layer có thể truy cập sử dụng `get_weights()` và `set_weight()` methods. Cho 1 dense layer,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MHpzP8tLneXj",
        "outputId": "fb2f7897-5f3b-4f2c-ef59-ba82f7fb9331"
      },
      "source": [
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dense_3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoqlJoabnoBW",
        "outputId": "c85b4006-fd04-4c9b-8a3d-24000c0ad353"
      },
      "source": [
        "weights,biases = hidden1.get_weights()\n",
        "weights,biases"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.0005345 ,  0.00498553, -0.04696542, ..., -0.05928578,\n",
              "         -0.05497381, -0.00498167],\n",
              "        [-0.03369472,  0.02008576,  0.04843073, ...,  0.05799256,\n",
              "          0.01170295,  0.05574577],\n",
              "        [-0.029352  , -0.04999067, -0.07065158, ...,  0.02025097,\n",
              "         -0.0068943 ,  0.06516817],\n",
              "        ...,\n",
              "        [-0.01703921, -0.02488277, -0.05525932, ..., -0.00451799,\n",
              "          0.04649175, -0.06104958],\n",
              "        [-0.02767918,  0.02626684,  0.00692876, ..., -0.02400315,\n",
              "         -0.03385001,  0.04598913],\n",
              "        [-0.03571031, -0.01906472,  0.05766597, ..., -0.06856182,\n",
              "          0.02119299,  0.04947263]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoIldtlon0up",
        "outputId": "8c7a6a8a-2a38-4aed-bc6a-e8b315dd8ea9"
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEuLBQ4Vn_Uy",
        "outputId": "9695a905-23ed-423b-e9b8-2933de4aa432"
      },
      "source": [
        "biases.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxx1aMlJoAbq"
      },
      "source": [
        "#### Compiling the Model\n",
        "Sau khi 1 model đã được tạo, bạn cần phải `compile()` chúng để chỉ định loss fnc và optimizer để sử dụng. chúng ta có thể tuỳ ý chỉ đihcj list metrics để tính trong suất huấn luyện và evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQZ1EZLkoztn"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAKOqCHopDvZ"
      },
      "source": [
        "Code ở trên chúng ta cùng giải thích 1 chút nhé. \n",
        "1. chúng ta sử dụng \"sparse_categorical_crosentropy\" lss bởi vì chúng ta đang làm phân loại cho mỗi lớp khác biệt. Nếu chúng ta sử dụng binarry classification  chúng ta có thể sử dụng **\"sigmoid\"** activation trong output thay vì  **\"softmatx\"** activation , và chúng ta sử dụng loss fnc là **\"binary_crossentropy\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxItNsq3pynn"
      },
      "source": [
        "#### Trainning and evaluating the model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew46LD9DqCZi",
        "outputId": "1816eaba-c320-4ad6-b9b8-a135dec49ec3"
      },
      "source": [
        "history = model.fit(X_train,y_train\n",
        "                    ,epochs=30\n",
        "                    ,validation_data=(X_valid,y_valid)\n",
        "                    )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 2ms/step - loss: 0.7001 - accuracy: 0.7692 - val_loss: 0.5243 - val_accuracy: 0.8152\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4824 - accuracy: 0.8325 - val_loss: 0.4343 - val_accuracy: 0.8574\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4385 - accuracy: 0.8469 - val_loss: 0.3999 - val_accuracy: 0.8644\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4114 - accuracy: 0.8565 - val_loss: 0.4033 - val_accuracy: 0.8614\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3916 - accuracy: 0.8624 - val_loss: 0.3736 - val_accuracy: 0.8722\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3758 - accuracy: 0.8680 - val_loss: 0.3756 - val_accuracy: 0.8652\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3652 - accuracy: 0.8704 - val_loss: 0.3583 - val_accuracy: 0.8742\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3524 - accuracy: 0.8746 - val_loss: 0.3484 - val_accuracy: 0.8754\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3419 - accuracy: 0.8777 - val_loss: 0.3680 - val_accuracy: 0.8706\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3317 - accuracy: 0.8817 - val_loss: 0.3477 - val_accuracy: 0.8770\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3229 - accuracy: 0.8852 - val_loss: 0.3381 - val_accuracy: 0.8768\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3159 - accuracy: 0.8863 - val_loss: 0.3563 - val_accuracy: 0.8698\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3089 - accuracy: 0.8893 - val_loss: 0.3225 - val_accuracy: 0.8822\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3020 - accuracy: 0.8921 - val_loss: 0.3256 - val_accuracy: 0.8802\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2944 - accuracy: 0.8941 - val_loss: 0.3363 - val_accuracy: 0.8790\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2885 - accuracy: 0.8974 - val_loss: 0.3305 - val_accuracy: 0.8822\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2821 - accuracy: 0.8981 - val_loss: 0.3321 - val_accuracy: 0.8800\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2782 - accuracy: 0.8997 - val_loss: 0.3076 - val_accuracy: 0.8868\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2723 - accuracy: 0.9024 - val_loss: 0.3115 - val_accuracy: 0.8874\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2665 - accuracy: 0.9041 - val_loss: 0.3081 - val_accuracy: 0.8874\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2626 - accuracy: 0.9055 - val_loss: 0.3028 - val_accuracy: 0.8894\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2582 - accuracy: 0.9078 - val_loss: 0.3059 - val_accuracy: 0.8906\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2541 - accuracy: 0.9083 - val_loss: 0.2937 - val_accuracy: 0.8930\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2489 - accuracy: 0.9105 - val_loss: 0.2946 - val_accuracy: 0.8924\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2445 - accuracy: 0.9109 - val_loss: 0.3413 - val_accuracy: 0.8724\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2411 - accuracy: 0.9122 - val_loss: 0.2898 - val_accuracy: 0.8928\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2370 - accuracy: 0.9143 - val_loss: 0.2989 - val_accuracy: 0.8922\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2317 - accuracy: 0.9160 - val_loss: 0.3061 - val_accuracy: 0.8896\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2292 - accuracy: 0.9175 - val_loss: 0.3008 - val_accuracy: 0.8896\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2248 - accuracy: 0.9187 - val_loss: 0.3259 - val_accuracy: 0.8808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz6tKJNvqRpp"
      },
      "source": [
        "Chúng ta pass validation sett(đây là option). Keras sẽ meassure the los and metrics on this test tại cuối của mỗi epoch, nó rất good để nhìn xem hiệu xuất.\n",
        "1. Nếu performane trên tập huấn luyện tốt hơn validation thì là overfitting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azustpnurbNw"
      },
      "source": [
        "Nếu tập huấn luyện khá bị lệch, một vài class đã được đại diện nhiều hơn nó có thể rất tốt hữu ích để set `class_weight` argument khi calling fit method.điều này sẽ tạo ra trọng số lớn hơn cho các nhóm đại diện ít và trọng số thấp hơn cho các nhóm đại diện quá . Các weights đó sử dụng bởi Keras khi tính the loss, néu bạn cần, mỗi per-instance weight hãy đặt `sample_weight` arguments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-pgsZ9Xt0Pr"
      },
      "source": [
        "Khi chúng ta có `fit()` methods nó sẽ trả về một History object \n",
        "1. (`history.paramse`) bao gồm tập huấn luyện parameters \n",
        "2. (`history.epoch`) list của epochs trong khi nó chạy\n",
        "3. quan trọngk alf history.history bao gồn los và thêm cả metriss nó meassured tại end epoch trên tập huấn luyện và trên validation set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "_teNtyW2uoGg",
        "outputId": "4dd81cda-10fc-43a6-b0f3-70839822b779"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1) # set y coordinate range to (0,1)\n",
        "plt.show();"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBnfrHX9u8ik"
      },
      "source": [
        "Bạn có thể nhìn cả 2 training accuracy and validation accuracy tăng đều đặn trong quá trình đào tạo , trong khi 2 cái kia nó giảm xuống. \n",
        "\n",
        "Thêm nữa validation curves thường gần với trainning curves, điều đó có nghĩa rằng là nó ko quá overfitting. \n",
        "\n",
        "**TIP**:When plotting the training curve, it should be shifted by half an epoch to the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdO6dvDIv5Oa",
        "outputId": "0d186eef-d7a6-4807-dd41-3d30c8c9b1d7"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 94.4273 - accuracy: 0.8059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[94.42727661132812, 0.805899977684021]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NVl8-3Hw3aC"
      },
      "source": [
        "Hay nhớ chống lại sự cám dỗ để điều chỉnh các siêu tham số trên bộ thử nghiệm, nếu không, ước tính của bạn về sai số tổng quát sẽ quá lạc qua"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlZscjQHxRu2"
      },
      "source": [
        "#### Using the model to make prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EayPIf1cxWkV",
        "outputId": "52e7d5f2-ea80-4712-cb3d-0ecf96abaaac"
      },
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKjSPEfixbNW"
      },
      "source": [
        "Nếu chúgn ta chỉ quan tân cái class mà có highest estimated probability ngay cả khi xác xuất của nó khác thất chúng ta có thể sử dụng `predict_classes()` methods instead:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XYZ_s3EyodK"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zvf49XPx3qn",
        "outputId": "0d767c91-4839-4261-c504-ce5c29231234"
      },
      "source": [
        "np.argmax(y_proba,axis=1) # take best value "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEFkSGtkx7b4",
        "outputId": "13816694-01c1-40e1-ab05-1168f377c559"
      },
      "source": [
        "np.array(class_names)[np.argmax(y_proba,axis=1)]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbttvBdoysyi"
      },
      "source": [
        "## BUilding a Regression MLP Using the Sequential API "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilxoGz2Sv1CU"
      },
      "source": [
        "nào chúng  ta California housing problem và sử dụng Neural network. Đơn giản, chúng ta sử dụng Sciki-Learn's `fea_california_housing()` load data. Dataset là đơn giản hơn chúng ta sử dụng, vì nó chỉ bao gồm các numerial featues. và k có mising valuie nhưng chúng ta đã bàn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyJNLVH_xrYD",
        "outputId": "59204e33-d99c-464b-dae9-839b34fab2e0"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Fetch the data set\n",
        "housing = fetch_california_housing()\n",
        "# split data to train_full and test set\n",
        "X_train_full,X_test,y_train_full,y_test = train_test_split(housing.data,housing.target)\n",
        "# split train_full  to train and valid set                                                 ,housing.target)\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X_train_full,y_train_full)\n",
        "# make Standardization preprocessing\n",
        "scaler = StandardScaler()\n",
        "# train from X set\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.fit_transform(X_test)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18AOIH_Zrgh",
        "outputId": "2eeb1fd9-08ac-462c-81a5-71d42fc6029a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11610, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEagBE-tZx2b",
        "outputId": "e8046925-b54c-4ae0-d274-eb2abcde2fd9"
      },
      "source": [
        "X_train.shape[1:]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-dy4I8QaKVl"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDL63nXbyZTL"
      },
      "source": [
        "Sử dụng Sequential API để xây dựng , và evaluate, và sử dụng MLP regression để dự đoán vì data k quá compilex nên chúng ta không cần phải sử dụng quá nhiều neurons như lúc trước để tránh overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISd_wm4PZgZ_",
        "outputId": "5c74faee-09d1-4bec-8745-d6e45c65655a"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "# 1. Creating a model\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]),\n",
        "                                 keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compiling model\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\"\n",
        "              ,optimizer=\"sgd\"\n",
        "              ,metrics=['mse'])\n",
        "# 3. Fitting the model\n",
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=20\n",
        "                    ,validation_data=(X_valid,y_valid))\n",
        "# 4. Evaluating model\n",
        "mse_test = model.evaluate(X_test,y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "y_pred"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7237 - mse: 0.7237 - val_loss: 1.0052 - val_mse: 1.0052\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8186 - mse: 0.8186 - val_loss: 0.4939 - val_mse: 0.4939\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4415 - mse: 0.4415 - val_loss: 0.4684 - val_mse: 0.4684\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - mse: 0.4149 - val_loss: 0.6618 - val_mse: 0.6618\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4102 - mse: 0.4102 - val_loss: 0.4339 - val_mse: 0.4339\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4152 - mse: 0.4152 - val_loss: 0.4326 - val_mse: 0.4326\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4171 - mse: 0.4171 - val_loss: 0.4246 - val_mse: 0.4246\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 0.4224 - val_mse: 0.4224\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - mse: 0.3792 - val_loss: 0.4215 - val_mse: 0.4215\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3764 - mse: 0.3764 - val_loss: 0.4136 - val_mse: 0.4136\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.4166 - val_mse: 0.4166\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - mse: 0.3697 - val_loss: 0.4129 - val_mse: 0.4129\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3642 - mse: 0.3642 - val_loss: 0.4076 - val_mse: 0.4076\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3649 - mse: 0.3649 - val_loss: 0.4028 - val_mse: 0.4028\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - mse: 0.3588 - val_loss: 0.3974 - val_mse: 0.3974\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 0.4146 - val_mse: 0.4146\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4027 - mse: 0.4027 - val_loss: 0.4007 - val_mse: 0.4007\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - mse: 0.3545 - val_loss: 0.3946 - val_mse: 0.3946\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - mse: 0.3530 - val_loss: 0.3983 - val_mse: 0.3983\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - mse: 0.3485 - val_loss: 0.3910 - val_mse: 0.3910\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 4.5736 - mse: 4.5736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0164127],\n",
              "       [6.1503987],\n",
              "       [1.7670097]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QQgbbWxbJ1f"
      },
      "source": [
        "Như bạn đã thấy, the Sequential API khá là dễ để sử dụng, Tuy nhiên **Sequential** model là rất chugn chung nó thường rất hữu ích để xây dưungj neural netwworkds với cấu trúc liên kết nó quá phức tạp. Vì mục đích này, Keras cung cấp **Functional API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qh4qdTQb9Dy"
      },
      "source": [
        "## Building Complex Models Using the Functional API\n",
        "Một ví dụ về  1 nonsequential neurral networks laf Wide & Deep neural netwwork. Đây là 1 kiến trúc mạng neral bởi 2016.Nó kết nối tất cả hoặc 1 phần của input ngay lập tức tới phần output layer. Kiến trúc nào có thể cho mạng neural để lơn cả 2 deep patterns. \n",
        "\n",
        "Chúng ta cùng build 1 neural netwwork để chưsng minh nó"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-3FTvkLdtOS"
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30,activation='relu')(input_)\n",
        "concat = keras.layers.Concatenate()([input_,hidden2])\n",
        "\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.Model(inputs=[input_],outputs=[output])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbqpULEXebUn"
      },
      "source": [
        "Nào chúng ta cùng giải thích code ở trên nhé\n",
        "1. Đầu tiên chúng ta tạo 1 object Input thông số mà input nhận được bao gồm **shape** và **dtype**. Một model có thể có nhiều inputs \n",
        "2. Tiếp theo, chúng ta tạo 1 Dense layer với 30 neurons, sử dụng ReLu activation function. Ngay khi nó đã tạo, nhớ rằng chúng ta call nó như 1 func và pasinh nó là input đó là tại sao nó được gọi là **Function API**. Nhớ rằng chúng ta chỉ nói với Keras làm thế nào nên kết nối layers toggerthe, chưa có thực sự data trong quá trình \n",
        "3. Chúng ta tạo cái hidden layer thứ 2, và chúng ta sử dụng func tiếp, Nhớ rằng chúg ta truyền nó là output của firrst layer \n",
        "4. Tiếp đến chúng ta tạo **Concatenate** laye, và một lần nữa chúng ta ngay lập tứ sử dụng như function. để nối input và output secon hidden layer, bạn có thể thích sử dụng `keras.layers.concatenate(input_here)`\n",
        "5. Rồi chúng ta tạo 1 output layer với single neuron và ko có activation function và hcusng gọi nó như 1 func và truyền nó kết quả của **concatenation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ozNLPoegYcH",
        "outputId": "1742ecf8-1fc5-4689-ab48-5c555ce414e7"
      },
      "source": [
        "# 2. Compiling model\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\"\n",
        "              ,optimizer=\"sgd\"\n",
        "              ,metrics=['mse'])\n",
        "# 3. Fitting the model\n",
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=20\n",
        "                    ,validation_data=(X_valid,y_valid))\n",
        "# 4. Evaluating model\n",
        "mse_test = model.evaluate(X_test,y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "y_pred"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7446 - mse: 0.7446 - val_loss: 2.8264 - val_mse: 2.8264\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 15.0664 - mse: 15.0664 - val_loss: 11.4746 - val_mse: 11.4746\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 4.9132 - mse: 4.9132 - val_loss: 42.2524 - val_mse: 42.2524\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "162/162 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4_XGtI0eXwA"
      },
      "source": [
        "Giả sử nếu chúng ta muốn gửi 1 subset features qua các wide path và 1 differn subset **wide path và 1 different subsep** hãy nhìn ở dưới:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxeEDrjiGz0"
      },
      "source": [
        "# 1. Creating 1 model \n",
        "input_A = keras.layers.Input(shape=[5],name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6],name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30,activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A,hidden2])\n",
        "output = keras.layers.Dense(1,name=\"output\")(concat)\n",
        "model = keras.Model(inputs=[input_A,input_B],outputs=[output])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJPtLEphit1y"
      },
      "source": [
        "Cái code ở trên cũng dã tự giản và chúng ta có thể làm bước 2 **compile** như bình thường nhưng đến chỗ **fit** thì chúng ta phải tách ra X_train_A, và X_train_B. và the same  cho evaluate và validation vì chúng ta tách thành 2 output mà"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0EoPhp8kLBb",
        "outputId": "813794e7-9507-4b5c-942a-6ef51c4b294c"
      },
      "source": [
        "some_test_concat = [1,2,3,4,5,6,7,8]\n",
        "some_test_concat[:5],some_test_concat[2:]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2, 3, 4, 5], [3, 4, 5, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszvR5vUjK2k",
        "outputId": "627ce81d-4a04-498d-ff0d-d41c65b83460"
      },
      "source": [
        "# 2. Compiling the model\n",
        "model.compile(loss='mse',optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "X_train_A, X_train_B  = X_train[:,:5], X_train[:,2:]\n",
        "X_valid_A, X_valid_B = X_valid[:,:5],X_valid[:,2:]\n",
        "X_test_A,X_test_B = X_test[:,:5],X_test[:,2:]\n",
        "X_new_A , X_new_B = X_test_A[:3],X_test_B[:3]\n",
        "history=  model.fit((X_train_A,X_train_B)\n",
        "                ,y_train\n",
        "                ,epochs=30\n",
        "                ,validation_data = ((X_valid_A,X_valid_B),y_valid))\n",
        "mse_test = model.evaluate((X_test_A,X_test_B),y_test)\n",
        "y_pred = model.predict((X_new_A,X_new_B))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.0587 - val_loss: 0.9427\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8178 - val_loss: 0.7052\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6809 - val_loss: 0.6421\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6298 - val_loss: 0.6097\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6000 - val_loss: 0.5876\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5777 - val_loss: 0.5701\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5601 - val_loss: 0.5578\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5472\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5336 - val_loss: 0.5391\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5231 - val_loss: 0.5328\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 0.5259\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5065 - val_loss: 0.5201\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.5151\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 0.5124\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4886 - val_loss: 0.5089\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4839 - val_loss: 0.5087\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4792 - val_loss: 0.4999\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4768 - val_loss: 0.4993\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4735 - val_loss: 0.4977\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4698 - val_loss: 0.4952\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4664 - val_loss: 0.4907\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4623 - val_loss: 0.4932\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4602 - val_loss: 0.4887\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4566 - val_loss: 0.4851\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4538 - val_loss: 0.4834\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4512 - val_loss: 0.4822\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4781\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4472 - val_loss: 0.4785\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4440 - val_loss: 0.4786\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4756\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.6851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z34O0Wk-kpLZ"
      },
      "source": [
        "Có nhiều trường hợp sử dụng mà bạn có thể muốn có nhiều đầu ra\n",
        "1. Ví dụ chúng bạn có thể tìm chính xác địa điểm của phân loại của ảnh, và phân loại nó\n",
        "2. Bạn có thể có nhiều task đọc lập dựa tren cùng 1 loại dữ liệu, bạn có thể huấn luyện 1 neural network per task, nhưng trong nhiều trường hợp bạn sẽ nhận được kết quả tốt hơn trên tất cả cá task đc training bởi 1 single mạng neural với 1 out put trên 1 task. Đól à boiwr vì mạng nở ron có thể learn features trong đa ta trên nhiều task. Bạn có thể xử lý mutiple tas classification trên hình ảnh khuôn mặt sử dụng 1 output phân loại người ví dụ như cười hay ngạc nhiên 1 cáci khác chỉ định là có đeo kính hay k\n",
        "3. Một trường hợp sử dụng khác là như một kỹ thuật chính quy hóa (tức là một ràng buộc đào tạo có mục tiêu là giảm việc trang bị quá mức và do đó cải thiện khả năng tổng quát hóa của mô hình). Ví dụ: bạn có thể muốn thêm một số đầu ra phụ trợ trong kiến trúc mạng nơ-ron để đảm bảo rằng phần bên dưới của mạng tự học được điều gì đó hữu ích mà không cần dựa vào phần còn lại của mạng. \n",
        "\n",
        "Thêm 1 outputs nữa khác là dễ dàng chỉ cần connect chúng với layers của chúng ta là xong "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TO27vE9od5e"
      },
      "source": [
        "# 1. Creating 1 model \n",
        "input_A = keras.layers.Input(shape=[5],name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6],name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30,activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A,hidden2])\n",
        "output = keras.layers.Dense(1,name=\"output\")(concat)\n",
        "aux_output = keras.layers.Dense(1,name=\"aux_output\")(hidden2)\n",
        "model = keras.Model(inputs=[input_A,input_B],outputs=[output,aux_output])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FenGCeW3rc2G"
      },
      "source": [
        "MỖi output có cần mỗi chính nó los fnc vì vậy khi chúng ta compiling model chúng ta cần pas list của loses Chúng ta quan tâm nhiều hơn main output hơn auxiliarry outt put, vì chúng ta muốn main output loss hơn weight THật may chúng ta có thế set loss weights  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0KeWBUTr7lk"
      },
      "source": [
        "model.compile(loss=['mse','mse'],\n",
        "              loss_weights=[0.9,0.1]\n",
        "              ,optimizer='sgd')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEFbJHRcsDnS"
      },
      "source": [
        "baay gioc húng ta  training model, chúng ta cần cung cấp labesl cho mỗi out put "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAviCoY5sHe0",
        "outputId": "bb95c042-4eb9-43d3-ade3-16a85ffd16cc"
      },
      "source": [
        "history = model.fit([X_train_A,X_train_B]\n",
        "                    ,[y_train,y_train]\n",
        "                    ,epochs=20\n",
        "                    ,validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.9174 - output_loss: 0.7810 - aux_output_loss: 2.1446 - val_loss: 0.6015 - val_output_loss: 0.5288 - val_aux_output_loss: 1.2565\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5501 - output_loss: 0.4814 - aux_output_loss: 1.1678 - val_loss: 0.5428 - val_output_loss: 0.4840 - val_aux_output_loss: 1.0722\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5472 - output_loss: 0.4981 - aux_output_loss: 0.9892 - val_loss: 0.6111 - val_output_loss: 0.5732 - val_aux_output_loss: 0.9515\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4908 - output_loss: 0.4488 - aux_output_loss: 0.8679 - val_loss: 0.6363 - val_output_loss: 0.6059 - val_aux_output_loss: 0.9105\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4904 - output_loss: 0.4573 - aux_output_loss: 0.7878 - val_loss: 0.4826 - val_output_loss: 0.4496 - val_aux_output_loss: 0.7793\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4544 - output_loss: 0.4259 - aux_output_loss: 0.7112 - val_loss: 0.4669 - val_output_loss: 0.4383 - val_aux_output_loss: 0.7245\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4406 - output_loss: 0.4153 - aux_output_loss: 0.6680 - val_loss: 0.4534 - val_output_loss: 0.4273 - val_aux_output_loss: 0.6885\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4283 - output_loss: 0.4054 - aux_output_loss: 0.6345 - val_loss: 0.4509 - val_output_loss: 0.4276 - val_aux_output_loss: 0.6610\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4218 - output_loss: 0.4006 - aux_output_loss: 0.6131 - val_loss: 0.4470 - val_output_loss: 0.4252 - val_aux_output_loss: 0.6434\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4150 - output_loss: 0.3949 - aux_output_loss: 0.5960 - val_loss: 0.4410 - val_output_loss: 0.4204 - val_aux_output_loss: 0.6265\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4057 - output_loss: 0.3865 - aux_output_loss: 0.5784 - val_loss: 0.4380 - val_output_loss: 0.4187 - val_aux_output_loss: 0.6121\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3983 - output_loss: 0.3804 - aux_output_loss: 0.5592 - val_loss: 0.4287 - val_output_loss: 0.4096 - val_aux_output_loss: 0.6012\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3944 - output_loss: 0.3778 - aux_output_loss: 0.5444 - val_loss: 0.4240 - val_output_loss: 0.4053 - val_aux_output_loss: 0.5924\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3879 - output_loss: 0.3713 - aux_output_loss: 0.5368 - val_loss: 0.4214 - val_output_loss: 0.4031 - val_aux_output_loss: 0.5856\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3804 - output_loss: 0.3643 - aux_output_loss: 0.5248 - val_loss: 0.4077 - val_output_loss: 0.3893 - val_aux_output_loss: 0.5729\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3766 - output_loss: 0.3611 - aux_output_loss: 0.5157 - val_loss: 0.4129 - val_output_loss: 0.3968 - val_aux_output_loss: 0.5579\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3740 - output_loss: 0.3592 - aux_output_loss: 0.5075 - val_loss: 0.4173 - val_output_loss: 0.4014 - val_aux_output_loss: 0.5599\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3818 - output_loss: 0.3688 - aux_output_loss: 0.4982 - val_loss: 0.4077 - val_output_loss: 0.3915 - val_aux_output_loss: 0.5537\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3692 - output_loss: 0.3545 - aux_output_loss: 0.5011 - val_loss: 0.4128 - val_output_loss: 0.3978 - val_aux_output_loss: 0.5475\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3668 - output_loss: 0.3523 - aux_output_loss: 0.4971 - val_loss: 0.3986 - val_output_loss: 0.3827 - val_aux_output_loss: 0.5416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP1rGA-asbw0"
      },
      "source": [
        "Khi chusng ta `evaluate` model, keraas sex returntotal loss cũng như các losxx còn lại \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy-65LUjsimv",
        "outputId": "43bceb06-1692-4fb8-d01d-2c253f425b98"
      },
      "source": [
        "total_loss ,main_loss,aux_loss = model.evaluate([X_test_A,X_test_B]\n",
        "                                                ,[y_test,y_test])\n",
        "print(f\"The total loss: {total_loss}, main_loss: {main_loss}, aux_loss: {aux_loss}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 4.2807 - output_loss: 4.3655 - aux_output_loss: 3.5172\n",
            "The total loss: 4.280667304992676, main_loss: 4.365500450134277, aux_loss: 3.5171782970428467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jUI8jPSs9kw"
      },
      "source": [
        "Giống như trên, the `predict()` cũng sẽ return predictions cho mỗi output:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjC0Vg5Bs2Jo",
        "outputId": "9aac0f62-dde1-43bb-ee7c-549677992bf5"
      },
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])\n",
        "y_pred_main"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaa5e9f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0230756],\n",
              "       [5.879576 ],\n",
              "       [2.6791244]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvvUlOR4tIyO",
        "outputId": "a141377d-22ca-4473-e333-2b84f5009c07"
      },
      "source": [
        "y_pred_aux"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.7407196],\n",
              "       [5.679032 ],\n",
              "       [2.9906013]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N1LU4AWtP4l"
      },
      "source": [
        "Như chúng ta đã thấy chúng ta có thể build bất kỳ cấu trúc nào chúgn ta sử dụng Function API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGEhg93JtZXh"
      },
      "source": [
        "## Using the Subclass API to Build Dynamic Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qgs-UwCuUga"
      },
      "source": [
        "Cả 2 Sequential API và Functional API là khai báo, bạn bắt đầu khai báo bới cái layer nàob mà bạn muốn sử dụng và chúng nên connect và chỉ khi đó, bạn mới có thể bắt đầu cung cấp cho mô hình một số dữ liệu để đào tạo hoặc suy luận. Có rất nhiều. Nhưng mặt trái của nó là static. Để muốn Dynamic hơn , thì Subclassing API sẽ dành cho bạn  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VBD5e97oR92"
      },
      "source": [
        "Đơn giản subclass the Model class, tạo  các lớp mà bạn cần trong constructor, và sử dụng chúng cho xử lý và tính toán bặn có sử dụng `call() ` dưới đây là ví dụ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqubafPZolam"
      },
      "source": [
        "class WideAndDeepModel(keras.Model):\n",
        "  def __init__(self,units=30,activation=\"relu\",**kwargs):\n",
        "    super().__init__(**kwargs) # handles standard args\n",
        "    self.hidden1 = keras.layers.Dense(units=units,activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(units=units,activation=activation)\n",
        "    self.main_output = keras.layers.Dense(1)\n",
        "    self.aux_output = keras.layers.Dense(1)\n",
        "  def call(self,inputs):\n",
        "    input_A,input_B = inputs\n",
        "    hidden1 = self.hidden1(input_B)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    concat = keras.layers.concatenate([input_A,hidden2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden2)\n",
        "    return main_output,aux_output\n",
        "model = WideAndDeepModel()\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE7Ae25Zpsq1"
      },
      "source": [
        "Code ở trên rất giống như thằng Functional API  ngoại trừ chúng ta không cần tạo inputs và chúng ta sử dụng input argument to `call()` method. Điểm khác biệt lớn nhất ở đây rằng bạn có thể làm những gì bạn muốn trong `call()` methods . Đây là 1 cái greate API cho nghiên cứ của experimenting với nhiều ý tưởng điên rồ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpoVjsiucMik"
      },
      "source": [
        "Cái flexible nào cũng có mặt hại của nó,  kiến trúc  model  của chúng ta m là hidden trong call method(), vì đó Keras không dễ dàn kiểm tra nó, nó không thể lưuu hoặc clone it, và khi nó gọi `summary`  method, nó chỉ lấy được danh sách layer, ngoại trừ bất kỳ thông tin trên làm sao để chúng ta kết nối được chúng. Moreover. Keras không thể kiểu tra types vvaf shape ở ngay đầu, nó có thể gây ra lỗi đầu. Vì vậy, trừ khi bạn thực sự cần sự linh hoạt bổ sung đó, bạn có thể nên sử dụng Sequential API hoặc Functional APi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc74-UCRdMZD"
      },
      "source": [
        "## Saving and Restoring a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDDrk-ISdUuK"
      },
      "source": [
        "Khi bạn sử dụng Sequential API hoặc FUnctionAPI, saving của 1 model Keras đã traiin là dễ dàng "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPDwDUredjZl"
      },
      "source": [
        "**chỉ cần**\n",
        "\n",
        "\n",
        "```\n",
        "model.save(\"my_keras_model.h5.\")\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702d8Qs6ecVQ",
        "outputId": "9671723e-03f3-4533-d5b6-97da62f57c06"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "# 1. Creating a model\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]),\n",
        "                                 keras.layers.Dense(1)\n",
        "])\n",
        "# 2. Compiling model\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\"\n",
        "              ,optimizer=\"sgd\"\n",
        "              ,metrics=['mse'])\n",
        "# 3. Fitting the model\n",
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=20\n",
        "                    ,validation_data=(X_valid,y_valid))\n",
        "# 4. Evaluating model\n",
        "mse_test = model.evaluate(X_test,y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "# 5. Saving model \n",
        "model.save(\"my_keras_model.h5\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7237 - mse: 0.7237 - val_loss: 1.0052 - val_mse: 1.0052\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8186 - mse: 0.8186 - val_loss: 0.4939 - val_mse: 0.4939\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4415 - mse: 0.4415 - val_loss: 0.4684 - val_mse: 0.4684\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - mse: 0.4149 - val_loss: 0.6618 - val_mse: 0.6618\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4102 - mse: 0.4102 - val_loss: 0.4339 - val_mse: 0.4339\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4152 - mse: 0.4152 - val_loss: 0.4326 - val_mse: 0.4326\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4171 - mse: 0.4171 - val_loss: 0.4246 - val_mse: 0.4246\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3832 - mse: 0.3832 - val_loss: 0.4224 - val_mse: 0.4224\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - mse: 0.3792 - val_loss: 0.4215 - val_mse: 0.4215\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3764 - mse: 0.3764 - val_loss: 0.4136 - val_mse: 0.4136\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - mse: 0.3736 - val_loss: 0.4166 - val_mse: 0.4166\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - mse: 0.3697 - val_loss: 0.4129 - val_mse: 0.4129\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3642 - mse: 0.3642 - val_loss: 0.4076 - val_mse: 0.4076\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3649 - mse: 0.3649 - val_loss: 0.4028 - val_mse: 0.4028\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - mse: 0.3588 - val_loss: 0.3974 - val_mse: 0.3974\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 0.4146 - val_mse: 0.4146\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4027 - mse: 0.4027 - val_loss: 0.4007 - val_mse: 0.4007\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - mse: 0.3545 - val_loss: 0.3946 - val_mse: 0.3946\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - mse: 0.3530 - val_loss: 0.3983 - val_mse: 0.3983\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - mse: 0.3485 - val_loss: 0.3910 - val_mse: 0.3910\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 4.5736 - mse: 4.5736\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faa580aa200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY2uS2CYdkN2"
      },
      "source": [
        "## Using CallBacks\n",
        "The `fit()` method có thể chấp nhận 1 call back argument thằng như 1 list của 1 dối thượng. nó sẽ gọi ngai khi start và end của trianing. At the start and end của mỗi eachpo, và thậm chí trước và sau khi xử lý each batch.\n",
        " Ví dụ dưới đây the `ModelCheckPoint` call back saves checkpoinst của model của trúng ta "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS2u1NAYd8hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf38467-fcaf-4918-9afb-50487dbe3496"
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
        "history = model.fit(X_train,y_train,epochs=10,callbacks=[checkpoint_cb])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3544 - mse: 0.3544\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3870 - mse: 0.3870\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3458 - mse: 0.3458\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3432 - mse: 0.3432\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3463 - mse: 0.3463\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3474 - mse: 0.3474\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3403 - mse: 0.3403\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3373 - mse: 0.3373\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - mse: 0.3400\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - mse: 0.3431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64fjLqdkeb2Z"
      },
      "source": [
        "Thêm nữa, nếu bạn sử dụng a validation set xuyên suốt durirng training, bạn có thể cài dặt `save_best_only = True` khi bạn tạo ModelCheckpoin. Trong trường hợp này, nó sẽ chỉ save yourr model khi nó peformance của validation set là tốt nhất. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzqjjOD7nsks",
        "outputId": "e0530204-17cd-4457-8756-7802d510fa51"
      },
      "source": [
        "checkpoint_cb= keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
        "                                               save_best_only=True)\n",
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=10\n",
        "                    ,validation_data=(X_valid,y_valid)\n",
        "                    ,callbacks=[checkpoint_cb])\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3366 - mse: 0.3366 - val_loss: 0.3827 - val_mse: 0.3827\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - mse: 0.3504 - val_loss: 0.3828 - val_mse: 0.3828\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3325 - mse: 0.3325 - val_loss: 0.3832 - val_mse: 0.3832\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3311 - mse: 0.3311 - val_loss: 0.4033 - val_mse: 0.4033\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - mse: 0.3327 - val_loss: 0.3819 - val_mse: 0.3819\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - mse: 0.3310 - val_loss: 0.3840 - val_mse: 0.3840\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3398 - mse: 0.3398 - val_loss: 0.3775 - val_mse: 0.3775\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3298 - mse: 0.3298 - val_loss: 0.3836 - val_mse: 0.3836\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - mse: 0.3329 - val_loss: 0.3855 - val_mse: 0.3855\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - mse: 0.3350 - val_loss: 0.3793 - val_mse: 0.3793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi-6BKc4nysR"
      },
      "source": [
        "Một cách khác để xử lý là sử dụng early stopping để sử dụng EarlyStopping cb. Đặc điểm của cái này là Nó sẽ làm gián đoạn quá trình đào tạo khi nó không đo lường được tiến bộ nào trên bộ xác thực cho một số kỷ nguyên định nghãi bởi patience arguement. Nó sẽ là optionall rôlback to the best model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7x-MUzbpt4X",
        "outputId": "52548834-b868-40e1-9fd7-8be21f13ece4"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=100,validation_data=(X_valid,y_valid),\n",
        "                    callbacks = [checkpoint_cb,early_stopping_cb])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3378 - mse: 0.3378 - val_loss: 0.3834 - val_mse: 0.3834\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3808 - mse: 0.3808 - val_loss: 0.3802 - val_mse: 0.3802\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3382 - mse: 0.3382 - val_loss: 0.3987 - val_mse: 0.3987\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3295 - mse: 0.3295 - val_loss: 0.4143 - val_mse: 0.4143\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3282 - mse: 0.3282 - val_loss: 0.3779 - val_mse: 0.3779\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3267 - mse: 0.3267 - val_loss: 0.3796 - val_mse: 0.3796\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3795 - mse: 0.3795 - val_loss: 0.3891 - val_mse: 0.3891\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.3873 - val_mse: 0.3873\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3346 - mse: 0.3346 - val_loss: 0.3853 - val_mse: 0.3853\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3313 - mse: 0.3313 - val_loss: 0.3801 - val_mse: 0.3801\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3321 - mse: 0.3321 - val_loss: 0.3801 - val_mse: 0.3801\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3290 - mse: 0.3290 - val_loss: 0.3796 - val_mse: 0.3796\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - mse: 0.3330 - val_loss: 0.3791 - val_mse: 0.3791\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3294 - mse: 0.3294 - val_loss: 0.3723 - val_mse: 0.3723\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3230 - mse: 0.3230 - val_loss: 0.3713 - val_mse: 0.3713\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3215 - mse: 0.3215 - val_loss: 0.3667 - val_mse: 0.3667\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3197 - mse: 0.3197 - val_loss: 0.3694 - val_mse: 0.3694\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3183 - mse: 0.3183 - val_loss: 0.3667 - val_mse: 0.3667\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3166 - mse: 0.3166 - val_loss: 0.3674 - val_mse: 0.3674\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3163 - mse: 0.3163 - val_loss: 0.3616 - val_mse: 0.3616\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3155 - mse: 0.3155 - val_loss: 0.3637 - val_mse: 0.3637\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3140 - mse: 0.3140 - val_loss: 0.3776 - val_mse: 0.3776\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3176 - mse: 0.3176 - val_loss: 0.3646 - val_mse: 0.3646\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3141 - mse: 0.3141 - val_loss: 0.3687 - val_mse: 0.3687\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3131 - mse: 0.3131 - val_loss: 0.3683 - val_mse: 0.3683\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3117 - mse: 0.3117 - val_loss: 0.3657 - val_mse: 0.3657\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3109 - mse: 0.3109 - val_loss: 0.3652 - val_mse: 0.3652\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3101 - mse: 0.3101 - val_loss: 0.3657 - val_mse: 0.3657\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3091 - mse: 0.3091 - val_loss: 0.3585 - val_mse: 0.3585\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3103 - mse: 0.3103 - val_loss: 0.3622 - val_mse: 0.3622\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3107 - mse: 0.3107 - val_loss: 0.3761 - val_mse: 0.3761\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3076 - mse: 0.3076 - val_loss: 0.3686 - val_mse: 0.3686\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3071 - mse: 0.3071 - val_loss: 0.3711 - val_mse: 0.3711\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3077 - mse: 0.3077 - val_loss: 0.3647 - val_mse: 0.3647\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3093 - mse: 0.3093 - val_loss: 0.3563 - val_mse: 0.3563\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3063 - mse: 0.3063 - val_loss: 0.3704 - val_mse: 0.3704\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3059 - mse: 0.3059 - val_loss: 0.3531 - val_mse: 0.3531\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3057 - mse: 0.3057 - val_loss: 0.3584 - val_mse: 0.3584\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3056 - mse: 0.3056 - val_loss: 0.3537 - val_mse: 0.3537\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3053 - mse: 0.3053 - val_loss: 0.3615 - val_mse: 0.3615\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3058 - mse: 0.3058 - val_loss: 0.3602 - val_mse: 0.3602\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3042 - mse: 0.3042 - val_loss: 0.3595 - val_mse: 0.3595\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3035 - mse: 0.3035 - val_loss: 0.3835 - val_mse: 0.3835\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3057 - mse: 0.3057 - val_loss: 0.3524 - val_mse: 0.3524\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3055 - mse: 0.3055 - val_loss: 0.3490 - val_mse: 0.3490\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3031 - mse: 0.3031 - val_loss: 0.3504 - val_mse: 0.3504\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3054 - mse: 0.3054 - val_loss: 0.3573 - val_mse: 0.3573\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3037 - mse: 0.3037 - val_loss: 0.3579 - val_mse: 0.3579\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3031 - mse: 0.3031 - val_loss: 0.3691 - val_mse: 0.3691\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3017 - mse: 0.3017 - val_loss: 0.3575 - val_mse: 0.3575\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3015 - mse: 0.3015 - val_loss: 0.3568 - val_mse: 0.3568\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3011 - mse: 0.3011 - val_loss: 0.3521 - val_mse: 0.3521\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3027 - mse: 0.3027 - val_loss: 0.3615 - val_mse: 0.3615\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - mse: 0.3034 - val_loss: 0.3636 - val_mse: 0.3636\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3014 - mse: 0.3014 - val_loss: 0.3528 - val_mse: 0.3528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6VIeuZNqE-7"
      },
      "source": [
        "The number cuar epch có thể set to lớn value vì trainig sẽ dường lại khi nó thấy k còn quá trình nữa. trong trường hợp này không cầu restore the best model save bởi vì early stiopping call để tìm kiếm best weights và restore chúng ở cuối cùng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CzfQ9z6qTe9"
      },
      "source": [
        "Nếu bạn cần thêm các điều khiển, bạn có thê dễ dàng viết custom callbacks hiển thị chúng xuyến xuống trainign set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrnrBLMXq8XR"
      },
      "source": [
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs):\n",
        "    print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb3annEFrAAx",
        "outputId": "18902647-5963-4862-a4ad-be590cc6543a"
      },
      "source": [
        "history = model.fit(X_train\n",
        "                    ,y_train\n",
        "                    ,epochs=100,validation_data=(X_valid,y_valid),\n",
        "                    \n",
        "                    callbacks = [checkpoint_cb,early_stopping_cb,PrintValTrainRatioCallback()])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3030 - mse: 0.3030 - val_loss: 0.3603 - val_mse: 0.3603\n",
            "\n",
            "val/train: 1.19\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3019 - mse: 0.3019 - val_loss: 0.3538 - val_mse: 0.3538\n",
            "\n",
            "val/train: 1.17\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3020 - mse: 0.3020 - val_loss: 0.3536 - val_mse: 0.3536\n",
            "\n",
            "val/train: 1.17\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3008 - mse: 0.3008 - val_loss: 0.3551 - val_mse: 0.3551\n",
            "\n",
            "val/train: 1.18\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3025 - mse: 0.3025 - val_loss: 0.3613 - val_mse: 0.3613\n",
            "\n",
            "val/train: 1.19\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3033 - mse: 0.3033 - val_loss: 0.3596 - val_mse: 0.3596\n",
            "\n",
            "val/train: 1.19\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3038 - mse: 0.3038 - val_loss: 0.3538 - val_mse: 0.3538\n",
            "\n",
            "val/train: 1.16\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3005 - mse: 0.3005 - val_loss: 0.3641 - val_mse: 0.3641\n",
            "\n",
            "val/train: 1.21\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3010 - mse: 0.3010 - val_loss: 0.3578 - val_mse: 0.3578\n",
            "\n",
            "val/train: 1.19\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3004 - mse: 0.3004 - val_loss: 0.3545 - val_mse: 0.3545\n",
            "\n",
            "val/train: 1.18\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3006 - mse: 0.3006 - val_loss: 0.3559 - val_mse: 0.3559\n",
            "\n",
            "val/train: 1.18\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2990 - mse: 0.2990 - val_loss: 0.3580 - val_mse: 0.3580\n",
            "\n",
            "val/train: 1.20\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3000 - mse: 0.3000 - val_loss: 0.3563 - val_mse: 0.3563\n",
            "\n",
            "val/train: 1.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g5WBHQurTc0"
      },
      "source": [
        "## Using TensorBoard for Viz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JdzsNMjr77w"
      },
      "source": [
        "# Fine-Tuning Neural Network Hyperparameters\n",
        "Một trong những tính linh hoạt của neural networks cũng là 1 nhược điểm chính của bạn nó có quá nhiều hyperparrametesr để được điều chính.\n",
        "\n",
        "1 OPtion là chỉ đơn giản sử dụng thật nhièu cái combinations của hyperparametse và chọn cái best nhất như chúng ta đã làm ở validation set. ví dụ như là GridSearchCV hoặc RandomizedSearchCV để tìm kiếm hyperparameters như chúng ta đã làm. để làm được cái nàhy chúng ta cần phải waráp cái KEras model trong object giống thằng Scikit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWZNjYr9toau"
      },
      "source": [
        "def build_model(n_hidden=1,n_neurons=30,learning_rate = 3e-3,input_shape=[8]):\n",
        "  \"\"\"\n",
        "  Build model flexible make using GridSearchCV or randomize Search CV\n",
        "  \"\"\"\n",
        "  # 1. Creating a model\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons,activation='relu'))\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  # 2. Compiling model \n",
        "  optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss=\"mse\",optimizer=optimizer)\n",
        "  return model\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vE92-TQx4P1"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGol4XtjxGdI"
      },
      "source": [
        "# Chusng t sẽ tạo 1 **KerasRegressor** dựa trên build_model()\n",
        "keras_reg=  keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoEdhgZix52X"
      },
      "source": [
        "Giowf KerasRegressor Object là  đã bao gồm ảound Kẻas model sử dụng build_model(). Vì chúng ta không chỉ định bất kỳ hyperaparament khi chúng ta tạo hết nó chỉ sử dụng những cái parametewr dèaul "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtFs8bmNyF4i",
        "outputId": "f0f448ad-5ba9-4f2b-b982-e3737ebbb67d"
      },
      "source": [
        "keras_reg.fit(X_train,y_train,epochs=100\n",
        "              ,validation_data=(X_valid,y_valid)\n",
        "              ,callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "mse_test = keras_reg.score(X_test,y_test)\n",
        "y_pred = keras_reg.predict(X_new)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0771 - val_loss: 0.5684\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5491 - val_loss: 0.5223\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5074 - val_loss: 0.4996\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4816 - val_loss: 0.4879\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4661 - val_loss: 0.4741\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.4659\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4447 - val_loss: 0.4621\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4576\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4317 - val_loss: 0.4579\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4530\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4489\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4474\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4144 - val_loss: 0.4443\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.4417\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4398\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.4380\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4024 - val_loss: 0.4364\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.4341\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4353\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3965 - val_loss: 0.4310\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.4325\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4335\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.4276\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.4265\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4260\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.4258\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3842 - val_loss: 0.4217\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4216\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4215\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4215\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4218\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4153\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.4186\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4143\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.4138\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4117\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4120\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.4116\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.4088\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4096\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4110\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.4115\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.4078\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.4065\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.4066\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.4071\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.4024\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.4033\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.4027\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.4059\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.4025\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3986\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3573 - val_loss: 0.4070\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 0.3964\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3988\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.4023\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3980\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3978\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3957\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3951\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3977\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.4005\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3516 - val_loss: 0.4009\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.4010\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3913\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3937\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3912\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3905\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3899\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3895\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3495 - val_loss: 0.3974\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3457 - val_loss: 0.3876\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3895\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3879\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3899\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.3877\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3865\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3871\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3882\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.4142\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3850\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3882\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3876\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3874\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3847\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3854\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3430 - val_loss: 0.3871\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3891\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3830\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3896\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3898\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3906\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3891\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3906\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3855\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3880\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3829\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3845\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3858\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3926\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 3.9535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNPTWkQPybZE"
      },
      "source": [
        "Nhớ rằng bất kì parameter chúng ta pass tròn `fit()` method bạn sẽ truyền xuống dưới Keras model. cũng nhớ rằng score chính là ngược lại với MSE bởi vì SCikirt-Learn muốn scores không muông loses "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXi3w2jy7CN",
        "outputId": "78c092f2-a048-4ecd-bd68-029ba2c3730c"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "parram_distribs = {\n",
        "    \"n_hidden\" : [0,1,2,3],\n",
        "    \"n_neurons\": np.arange(1,100),\n",
        "    \"learning_rate\": reciprocal(3e-4,3e-2)\n",
        "}\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg,parram_distribs,n_iter=10,cv=3)\n",
        "rnd_search_cv.fit(X_train,y_train,epochs=100,\n",
        "                  validation_data=(X_valid,y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8604 - val_loss: 0.5775\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 1.8763\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.6632 - val_loss: 22.7248\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 13.3854 - val_loss: 346.8712\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 143.6692 - val_loss: 5304.4326\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 50194.1094 - val_loss: 80856.4375\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 490349.6875 - val_loss: 1419180.2500\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 10947239.0000 - val_loss: 19473216.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 143755184.0000 - val_loss: 292636704.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2425747712.0000 - val_loss: 4429023232.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 35474038784.0000 - val_loss: 80431808512.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 88085520384.0000\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4331 - val_loss: 5.7138\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.2380 - val_loss: 72.4291\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 28.5971 - val_loss: 1597.5459\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 900.2853 - val_loss: 31861.3242\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 17042.3223 - val_loss: 655130.9375\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1100571.6250 - val_loss: 13307834.0000\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 19285344.0000 - val_loss: 271710048.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 79913080.0000 - val_loss: 6310240256.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2042308352.0000 - val_loss: 112844423168.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 80946053120.0000 - val_loss: 2306566520832.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1502977458176.0000 - val_loss: 46797556809728.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 85629979328512.0000\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 8.0042 - val_loss: 353.1461\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 154516.6875 - val_loss: 327042.7500\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4052150.5000 - val_loss: 315212608.0000\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 6183356928.0000 - val_loss: 278026649600.0000\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 7746107211776.0000 - val_loss: 257765431836672.0000\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 103014850724102144.0000 - val_loss: 228946083571564544.0000\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 102259753485865058304.0000 - val_loss: 197993456860135424000.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2410221811877353095168.0000 - val_loss: 201787474256029517086720.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4861795621490026556162048.0000 - val_loss: 157721137569742563080929280.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 62377309136875202489996017664.0000 - val_loss: 140893154613229965669151277056.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3611935174325023818083366600704.0000 - val_loss: 123289156506266958346555123302400.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 4691481752724495378512487645184.0000\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4278 - val_loss: 0.6923\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6383 - val_loss: 0.5910\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5663 - val_loss: 0.5637\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5314 - val_loss: 0.5331\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.5229\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4856 - val_loss: 0.4989\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4667 - val_loss: 0.4884\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4788\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4726\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 0.4656\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4645\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4619\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4065 - val_loss: 0.4586\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4014 - val_loss: 0.4485\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4489\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3938 - val_loss: 0.4468\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.4529\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.4421\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.4373\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3835 - val_loss: 0.4359\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4393\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4343\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3764 - val_loss: 0.4470\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.4308\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.4318\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.4287\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.4288\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.4259\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4295\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3683 - val_loss: 0.4261\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3674 - val_loss: 0.4287\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.4249\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3654 - val_loss: 0.4251\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.4223\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3638 - val_loss: 0.4227\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3634 - val_loss: 0.4208\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4238\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.4220\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.4212\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3604 - val_loss: 0.4192\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.4189\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.4163\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.4207\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.4184\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.4183\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4200\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4152\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.4179\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4153\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4120\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4146\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4126\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4109\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4138\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4212\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.4108\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4110\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4153\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4112\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4116\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.4066\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.4099\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4087\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.4132\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.4071\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.4044\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4080\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.4063\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4094\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4086\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4081\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4045\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4075\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3476 - val_loss: 0.4061\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4062\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.4101\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3783\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4874 - val_loss: 0.9684\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7850 - val_loss: 0.6587\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6166 - val_loss: 0.6001\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 0.5507\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5313\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5042 - val_loss: 0.5097\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4885 - val_loss: 0.5018\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4795 - val_loss: 0.4953\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4737 - val_loss: 0.4904\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4690 - val_loss: 0.4885\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4651 - val_loss: 0.4841\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4616 - val_loss: 0.4812\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4587 - val_loss: 0.4851\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4558 - val_loss: 0.4834\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4814\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4517 - val_loss: 0.4716\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4826\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4457 - val_loss: 0.4702\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4684\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4673\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 0.4662\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4372 - val_loss: 0.4651\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4339 - val_loss: 0.4610\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4611\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4581\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4572\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4547\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4569\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.4551\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.4504\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4163 - val_loss: 0.4533\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4476\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.4465\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4463\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4442\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4416\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.4399\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.4384\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3954 - val_loss: 0.4379\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 0.4381\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.4368\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4370\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.4340\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4340\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.4313\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4285\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4275\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.4265\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.4264\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3763 - val_loss: 0.4255\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.4253\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.4251\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.4241\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4238\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4225\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.4206\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3682 - val_loss: 0.4196\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.4184\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.4184\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.4184\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.4163\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.4159\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.4164\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4147\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.4156\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.4137\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.4120\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4095\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4093\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.4101\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.4126\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.4088\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.4094\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.4084\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.4057\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.4072\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4064\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.4063\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.4025\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4025\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4068\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4008\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4042\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3448 - val_loss: 0.4039\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3995\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3429 - val_loss: 0.4030\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.4043\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.4015\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3980\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3965\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.4003\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3397 - val_loss: 0.3957\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.3930\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3956\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3370 - val_loss: 0.4041\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3921\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.3957\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3942\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3337 - val_loss: 0.3945\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3922\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3624\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5849 - val_loss: 0.8656\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8449 - val_loss: 0.7731\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7739 - val_loss: 0.7284\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7299 - val_loss: 0.6963\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6961 - val_loss: 0.6753\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6677 - val_loss: 0.6528\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6430 - val_loss: 0.6238\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6200 - val_loss: 0.6108\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5989 - val_loss: 0.5914\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5789 - val_loss: 0.5852\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5614 - val_loss: 0.5649\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5443 - val_loss: 0.5496\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5394\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5153 - val_loss: 0.5311\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5033 - val_loss: 0.5234\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4933 - val_loss: 0.5066\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.5029\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4765 - val_loss: 0.4917\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.4879\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4634 - val_loss: 0.4828\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4572 - val_loss: 0.4755\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4741\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4482 - val_loss: 0.4696\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4425 - val_loss: 0.4644\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4617\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4365 - val_loss: 0.4601\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4637\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4585\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4276 - val_loss: 0.4656\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4244 - val_loss: 0.4504\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4634\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4474\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4176 - val_loss: 0.4579\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4161 - val_loss: 0.4477\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.4445\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.4438\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4102 - val_loss: 0.4453\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4101 - val_loss: 0.4430\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4412\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4065 - val_loss: 0.4410\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4404\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.4359\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.4392\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3998 - val_loss: 0.4319\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.4303\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4319\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.4258\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4257\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4317\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4304\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4252\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3901 - val_loss: 0.4200\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4294\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4266\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.4222\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4224\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4173\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.4168\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4161\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.4160\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4194\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3783 - val_loss: 0.4145\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.4211\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.4142\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4170\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.4128\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4102\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.4107\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4072\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4065\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4085\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4094\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.4104\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.4102\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.4137\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.4035\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3674 - val_loss: 0.4091\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4063\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4070\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3662 - val_loss: 0.4048\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.4004\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.4015\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.4000\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.4029\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.4103\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.4014\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4021\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.4025\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.3983\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4049\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4036\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4011\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.3947\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.3995\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4059\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4005\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.3947\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4049\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.3954\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.3982\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3406\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.7141 - val_loss: 1.0366\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8957 - val_loss: 0.7593\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7555 - val_loss: 0.7094\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7123 - val_loss: 0.6785\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6799 - val_loss: 0.6539\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6519 - val_loss: 0.6295\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6272 - val_loss: 0.6123\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6057 - val_loss: 0.5924\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.5779\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5693 - val_loss: 0.5630\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5541 - val_loss: 0.5529\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.5420\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.5352\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5190 - val_loss: 0.5250\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.5211\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5024 - val_loss: 0.5148\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4957 - val_loss: 0.5114\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4895 - val_loss: 0.5054\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4843 - val_loss: 0.5001\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4798 - val_loss: 0.4991\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4752 - val_loss: 0.4986\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4714 - val_loss: 0.4925\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4677 - val_loss: 0.4924\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4649 - val_loss: 0.4886\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4617 - val_loss: 0.4876\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4590 - val_loss: 0.4852\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4560 - val_loss: 0.4821\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4539 - val_loss: 0.4818\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4514 - val_loss: 0.4818\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4783\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4472 - val_loss: 0.4785\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4767\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4741\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4717\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4726\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4377 - val_loss: 0.4716\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4697\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 0.4692\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4676\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4310 - val_loss: 0.4668\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4640\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 0.4627\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4264 - val_loss: 0.4640\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4248 - val_loss: 0.4622\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4236 - val_loss: 0.4618\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4602\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4207 - val_loss: 0.4604\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4192 - val_loss: 0.4599\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4582\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4561\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.4593\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.4562\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4130 - val_loss: 0.4531\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.4533\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4530\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4541\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4515\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.4528\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4065 - val_loss: 0.4498\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4054 - val_loss: 0.4493\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4046 - val_loss: 0.4483\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4034 - val_loss: 0.4496\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4025 - val_loss: 0.4465\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.4460\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4007 - val_loss: 0.4459\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3997 - val_loss: 0.4454\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3987 - val_loss: 0.4440\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4442\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.4420\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4421\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4434\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4410\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4411\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3925 - val_loss: 0.4403\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4399\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.4396\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4390\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4374\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.4385\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.4372\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.4370\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4379\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4338\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3844 - val_loss: 0.4337\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4332\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4328\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.4322\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4315\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.4300\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.4300\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.4300\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.4291\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3781 - val_loss: 0.4289\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4284\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.4270\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.4274\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4255\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.4259\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.4242\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3738 - val_loss: 0.4241\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3988\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.9250 - val_loss: 1.0176\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8947 - val_loss: 0.7811\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7496 - val_loss: 0.7085\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6884 - val_loss: 0.6610\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6458 - val_loss: 0.6282\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6136 - val_loss: 0.6024\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5878 - val_loss: 0.5828\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5677 - val_loss: 0.5664\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.5524\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5399\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5238 - val_loss: 0.5303\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5133 - val_loss: 0.5218\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5041 - val_loss: 0.5152\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.5085\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4892 - val_loss: 0.5034\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4836 - val_loss: 0.4986\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4780 - val_loss: 0.4955\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4734 - val_loss: 0.4916\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 0.4896\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4655 - val_loss: 0.4872\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 0.4836\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4591 - val_loss: 0.4823\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4798\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4530 - val_loss: 0.4774\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.4765\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4737\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4455 - val_loss: 0.4726\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4431 - val_loss: 0.4714\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4405 - val_loss: 0.4687\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4382 - val_loss: 0.4667\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4364 - val_loss: 0.4671\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4342 - val_loss: 0.4647\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4323 - val_loss: 0.4637\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4628\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.4617\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.4597\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4248 - val_loss: 0.4587\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4229 - val_loss: 0.4583\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.4573\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4555\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4180 - val_loss: 0.4545\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4537\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4150 - val_loss: 0.4539\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4519\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4522\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.4504\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4491\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4486\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4470\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4055 - val_loss: 0.4464\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4467\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4461\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4448\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4440\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4432\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.4430\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4412\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.4409\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.4408\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4397\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.4383\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.4383\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.4381\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4366\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3906 - val_loss: 0.4356\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.4348\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.4350\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3882 - val_loss: 0.4339\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.4332\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3866 - val_loss: 0.4339\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3860 - val_loss: 0.4328\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3856 - val_loss: 0.4319\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4334\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3838 - val_loss: 0.4309\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.4304\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4307\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.4293\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.4296\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.4287\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.4281\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4271\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4281\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4261\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.4251\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4253\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.4255\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.4256\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4254\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3752 - val_loss: 0.4236\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.4236\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4234\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4232\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.4227\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.4225\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.4221\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4219\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.4204\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.4221\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3707 - val_loss: 0.4195\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3702 - val_loss: 0.4197\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3884\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2840 - val_loss: 0.8665\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7783 - val_loss: 0.6843\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6853 - val_loss: 0.6565\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6528 - val_loss: 0.6305\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6261 - val_loss: 0.6138\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6026 - val_loss: 0.5898\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5820 - val_loss: 0.5718\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5627 - val_loss: 0.5596\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5460 - val_loss: 0.5435\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5311 - val_loss: 0.5327\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5178 - val_loss: 0.5221\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5066 - val_loss: 0.5120\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4969 - val_loss: 0.5059\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4882 - val_loss: 0.4987\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4816 - val_loss: 0.4923\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4754 - val_loss: 0.4884\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4702 - val_loss: 0.4845\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4651 - val_loss: 0.4796\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4608 - val_loss: 0.4807\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4574 - val_loss: 0.4768\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4538 - val_loss: 0.4711\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4508 - val_loss: 0.4710\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4480 - val_loss: 0.4672\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4451 - val_loss: 0.4659\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4655\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4403 - val_loss: 0.4609\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4391 - val_loss: 0.4623\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4368 - val_loss: 0.4610\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4351 - val_loss: 0.4598\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4333 - val_loss: 0.4558\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4317 - val_loss: 0.4577\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4303 - val_loss: 0.4557\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 0.4569\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4276 - val_loss: 0.4526\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4512\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4248 - val_loss: 0.4485\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4506\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4508\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.4496\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4487\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4454\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4459\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.4456\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4436\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4147 - val_loss: 0.4442\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.4449\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4119 - val_loss: 0.4389\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4116 - val_loss: 0.4387\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.4386\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4095 - val_loss: 0.4397\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4381\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4356\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4065 - val_loss: 0.4394\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4058 - val_loss: 0.4361\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4366\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4357\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.4332\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.4324\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4326\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4322\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4319\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3998 - val_loss: 0.4316\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4306\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4303\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4315\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4292\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.4284\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4287\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.4276\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3940 - val_loss: 0.4265\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3941 - val_loss: 0.4267\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 0.4280\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3925 - val_loss: 0.4254\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.4255\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4240\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4228\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3901 - val_loss: 0.4247\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3899 - val_loss: 0.4251\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.4219\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4216\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.4201\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.4204\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.4188\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3867 - val_loss: 0.4199\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.4226\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4178\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.4191\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.4208\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.4200\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3844 - val_loss: 0.4181\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4185\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.4157\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.4157\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.4154\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.4155\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.4152\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.4135\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3810 - val_loss: 0.4136\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3809 - val_loss: 0.4137\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.4129\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3592\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2210 - val_loss: 1.0214\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8769 - val_loss: 0.7250\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6769 - val_loss: 0.6449\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6236 - val_loss: 0.6133\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5957 - val_loss: 0.5951\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5740 - val_loss: 0.5767\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5551 - val_loss: 0.5676\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5392 - val_loss: 0.5509\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5401\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5099 - val_loss: 0.5289\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4966 - val_loss: 0.5219\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4840 - val_loss: 0.5100\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4718 - val_loss: 0.5039\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4611 - val_loss: 0.4912\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4518 - val_loss: 0.4859\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4432 - val_loss: 0.4802\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4353 - val_loss: 0.4813\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4288 - val_loss: 0.4688\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4632\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4598\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4614\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4523\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4558\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4466\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4455\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3919 - val_loss: 0.4408\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4379\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.4366\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.4363\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3798 - val_loss: 0.4321\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.4307\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.4298\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3722 - val_loss: 0.4264\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.4233\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4234\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.4205\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4203\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4196\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4165\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4142\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.4140\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4116\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4119\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4101\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4087\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4080\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4067\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4075\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4044\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4023\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.4034\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4009\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3984\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.3985\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.4001\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3976\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3383 - val_loss: 0.3960\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3377 - val_loss: 0.3984\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.3944\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3939\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3928\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3951\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3914\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3909\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3895\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.3891\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3306 - val_loss: 0.3880\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3884\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.3872\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3885\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3878\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.3854\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3839\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3257 - val_loss: 0.3843\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3841\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3840\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3853\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3228 - val_loss: 0.3830\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3812\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3802\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3805\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3802\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3802\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3790\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3191 - val_loss: 0.3772\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.3766\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3793\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3172 - val_loss: 0.3784\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3764\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3761\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3747\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3750\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3763\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3743\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3747\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.3741\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3758\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3723\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3728\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3723\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3487\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8152 - val_loss: 1.1252\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9060 - val_loss: 0.7639\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7154 - val_loss: 0.7019\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6689 - val_loss: 0.6617\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6351 - val_loss: 0.6358\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6072 - val_loss: 0.6113\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5835 - val_loss: 0.5926\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5634 - val_loss: 0.5794\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5458 - val_loss: 0.5610\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5474\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5140 - val_loss: 0.5346\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 0.5253\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4891 - val_loss: 0.5184\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4788 - val_loss: 0.5060\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4697 - val_loss: 0.4995\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4632 - val_loss: 0.4944\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4541 - val_loss: 0.4894\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4483 - val_loss: 0.4800\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4803\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4367 - val_loss: 0.4748\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.4675\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4672\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4216 - val_loss: 0.4618\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4581\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4569\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4515\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4510\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4474\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4441\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4400\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4423\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.4374\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 0.4361\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.4346\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4337\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.4311\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4288\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.4267\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3773 - val_loss: 0.4251\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4221\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4199\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.4220\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4214\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4180\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4168\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4142\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4111\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.4110\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4084\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4070\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4085\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4067\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4046\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4054\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4041\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4024\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3997\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3993\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.3989\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3999\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3966\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3950\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.3968\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.3954\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3419 - val_loss: 0.3931\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3927\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3921\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.3904\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.3891\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3375 - val_loss: 0.3914\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3370 - val_loss: 0.3901\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3885\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3902\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3884\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3335 - val_loss: 0.3873\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3892\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3854\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.3872\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.3831\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3295 - val_loss: 0.3847\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3857\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3827\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.3828\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3836\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3797\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3257 - val_loss: 0.3808\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.3839\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3810\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3784\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3233 - val_loss: 0.3792\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3807\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3759\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3746\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3203 - val_loss: 0.3758\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.3789\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3756\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3740\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3763\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3741\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3731\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3357\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2289 - val_loss: 1.0051\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8576 - val_loss: 0.6983\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6705 - val_loss: 0.6375\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6104 - val_loss: 0.5953\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5735 - val_loss: 0.5741\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5461 - val_loss: 0.5508\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5251 - val_loss: 0.5306\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5082 - val_loss: 0.5227\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.5087\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4822 - val_loss: 0.5087\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.4980\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4639 - val_loss: 0.4877\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.4851\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4497 - val_loss: 0.4808\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4443 - val_loss: 0.4738\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4396 - val_loss: 0.4694\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4344 - val_loss: 0.4668\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4299 - val_loss: 0.4590\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4260 - val_loss: 0.4584\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4559\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4487\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4485\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4451\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4437\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4396\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4374\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4417\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4346\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4390\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.4284\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4375\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3919 - val_loss: 0.4270\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3893 - val_loss: 0.4324\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4236\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4208\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.4176\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4235\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.4198\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.4181\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3784 - val_loss: 0.4201\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.4163\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4135\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4157\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4099\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.4096\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.4099\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.4036\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4041\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4081\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4070\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.4021\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.3997\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.4068\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4018\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.4002\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4000\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.3957\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.3953\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3956\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.3951\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3961\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.3936\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3944\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.3941\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3957\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.3926\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3909\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3925\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3898\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3893\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.3904\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3922\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.3888\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3910\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.3896\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3848\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3898\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3428 - val_loss: 0.3885\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 0.3859\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3853\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3817\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3397 - val_loss: 0.3848\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3824\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3842\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3389 - val_loss: 0.3894\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3815\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3370 - val_loss: 0.3819\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.3856\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3831\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3849\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.3863\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3801\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3777\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3766\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3341 - val_loss: 0.3777\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3810\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3753\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3788\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3763\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3766\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3247\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.9717 - val_loss: 1.3758\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0708 - val_loss: 0.8299\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7681 - val_loss: 0.7091\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6829 - val_loss: 0.6528\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6367 - val_loss: 0.6235\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6080 - val_loss: 0.6029\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5882 - val_loss: 0.5909\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5739 - val_loss: 0.5784\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5611 - val_loss: 0.5700\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5504 - val_loss: 0.5601\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5402 - val_loss: 0.5563\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.5468\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5229 - val_loss: 0.5433\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5152 - val_loss: 0.5324\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5080 - val_loss: 0.5278\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 0.5239\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4942 - val_loss: 0.5233\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4882 - val_loss: 0.5132\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4827 - val_loss: 0.5076\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4778 - val_loss: 0.5055\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4727 - val_loss: 0.5089\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4683 - val_loss: 0.4995\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4636 - val_loss: 0.5032\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4606 - val_loss: 0.4963\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4573 - val_loss: 0.4941\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4541 - val_loss: 0.4908\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4510 - val_loss: 0.4879\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4487 - val_loss: 0.4869\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4464 - val_loss: 0.4874\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4439 - val_loss: 0.4837\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4418 - val_loss: 0.4841\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4393 - val_loss: 0.4840\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4809\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4353 - val_loss: 0.4766\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.4778\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4319 - val_loss: 0.4766\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4761\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4284 - val_loss: 0.4764\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4269 - val_loss: 0.4727\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4253 - val_loss: 0.4735\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4240 - val_loss: 0.4694\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.4675\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4677\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4674\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4665\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4654\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4642\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4646\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4651\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4608\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4636\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4613\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4572\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4575\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4554\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4589\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4562\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4594\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4525\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4515\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4519\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4548\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4490\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 0.4488\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3959 - val_loss: 0.4486\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4459\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4475\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4445\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4445\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4485\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4441\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4440\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 0.4431\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.4439\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4424\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.4415\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4406\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4410\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4407\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4392\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4437\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4365\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3816 - val_loss: 0.4376\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3811 - val_loss: 0.4377\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3804 - val_loss: 0.4379\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3798 - val_loss: 0.4359\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.4367\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4350\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4353\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.4372\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4351\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4342\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.4345\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4317\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.4332\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.4298\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.4298\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.4276\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.4287\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4029\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.8324 - val_loss: 1.4319\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1089 - val_loss: 0.7894\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7408 - val_loss: 0.7024\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6811 - val_loss: 0.6726\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6536 - val_loss: 0.6511\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6321 - val_loss: 0.6322\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6141 - val_loss: 0.6187\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5991 - val_loss: 0.6025\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5852 - val_loss: 0.5897\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5728 - val_loss: 0.5777\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5612 - val_loss: 0.5675\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5508 - val_loss: 0.5581\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5412 - val_loss: 0.5510\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5325 - val_loss: 0.5409\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.5352\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5172 - val_loss: 0.5260\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.5237\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5046 - val_loss: 0.5158\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.5121\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4942 - val_loss: 0.5080\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4898 - val_loss: 0.5037\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4855 - val_loss: 0.5008\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4815 - val_loss: 0.4956\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4785 - val_loss: 0.4934\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4751 - val_loss: 0.4904\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4726 - val_loss: 0.4889\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4699 - val_loss: 0.4857\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4678 - val_loss: 0.4861\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4643 - val_loss: 0.4835\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4646 - val_loss: 0.4816\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4607 - val_loss: 0.4829\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4586 - val_loss: 0.4793\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4579 - val_loss: 0.4788\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4545 - val_loss: 0.4767\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4548 - val_loss: 0.4765\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4520 - val_loss: 0.4733\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4498 - val_loss: 0.4719\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4481 - val_loss: 0.4705\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4468 - val_loss: 0.4713\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4437 - val_loss: 0.4704\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4692\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4693\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.4685\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4390 - val_loss: 0.4674\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4363 - val_loss: 0.4665\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4651\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4372 - val_loss: 0.4634\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4328 - val_loss: 0.4625\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4305 - val_loss: 0.4614\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4306 - val_loss: 0.4599\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4278 - val_loss: 0.4626\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4292 - val_loss: 0.4610\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4276 - val_loss: 0.4595\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4245 - val_loss: 0.4580\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.4573\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4567\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4552\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4548\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4533\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4538\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4532\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4538\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.4519\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4521\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4489\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4501\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4504\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4482\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4478\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4496\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4464\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4472\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4471\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4459\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4455\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4446\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4454\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4003 - val_loss: 0.4445\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3987 - val_loss: 0.4419\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.4431\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4416\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4412\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4407\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4415\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4394\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4401\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4402\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4382\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4381\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.4373\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3905 - val_loss: 0.4364\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 0.4358\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.4363\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4363\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4355\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4336\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4337\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4332\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4332\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4012\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.8466 - val_loss: 1.2986\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1253 - val_loss: 0.8865\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8894 - val_loss: 0.8269\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8403 - val_loss: 0.8044\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8158 - val_loss: 0.7879\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7970 - val_loss: 0.7718\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7802 - val_loss: 0.7568\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7633 - val_loss: 0.7465\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7487 - val_loss: 0.7309\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7337 - val_loss: 0.7202\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7201 - val_loss: 0.7079\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7072 - val_loss: 0.6959\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6939 - val_loss: 0.6889\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6825 - val_loss: 0.6744\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6702 - val_loss: 0.6646\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6590 - val_loss: 0.6549\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6479 - val_loss: 0.6461\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6371 - val_loss: 0.6363\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6260 - val_loss: 0.6304\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6163 - val_loss: 0.6206\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6066 - val_loss: 0.6109\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5977 - val_loss: 0.6032\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5887 - val_loss: 0.5949\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5796 - val_loss: 0.5876\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5711 - val_loss: 0.5816\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5628 - val_loss: 0.5722\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5560 - val_loss: 0.5690\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 0.5604\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5410 - val_loss: 0.5551\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5344 - val_loss: 0.5461\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5446\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.5363\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5328\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5077 - val_loss: 0.5271\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5011 - val_loss: 0.5178\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.5123\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4906 - val_loss: 0.5084\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4848 - val_loss: 0.5042\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4792 - val_loss: 0.5009\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4742 - val_loss: 0.4980\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4747 - val_loss: 0.4941\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4695 - val_loss: 0.4920\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4641 - val_loss: 0.4878\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4595 - val_loss: 0.4820\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4610 - val_loss: 0.4840\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4557 - val_loss: 0.4781\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.4753\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4491 - val_loss: 0.4724\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4449 - val_loss: 0.4724\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4717\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4436 - val_loss: 0.4689\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4378 - val_loss: 0.4625\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4362 - val_loss: 0.4672\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4353 - val_loss: 0.4622\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4323 - val_loss: 0.4594\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4288 - val_loss: 0.4562\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4271 - val_loss: 0.4553\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4321 - val_loss: 0.4556\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4257 - val_loss: 0.4522\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4510\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4536\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4248 - val_loss: 0.4493\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4489\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4468\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4503\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4495\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4459\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4433\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4428\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4401\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4400\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4421\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4384\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4390\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4390\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4355\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4352\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4349\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4333\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.4307\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.4280\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4288\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4280\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4279\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4338\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.4248\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3893 - val_loss: 0.4280\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.4292\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.4238\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4232\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3863 - val_loss: 0.4263\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4224\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.4252\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.4227\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4217\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4212\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.4199\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.4187\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.4172\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3778 - val_loss: 0.4174\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3598\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6796 - val_loss: 0.8488\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7747 - val_loss: 0.6789\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6500 - val_loss: 0.6176\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5899 - val_loss: 0.5776\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5537 - val_loss: 0.5592\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5360\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5087 - val_loss: 0.5247\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.5118\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4793 - val_loss: 0.5028\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4674 - val_loss: 0.4937\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4567 - val_loss: 0.4895\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4472 - val_loss: 0.4820\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4384 - val_loss: 0.4763\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4303 - val_loss: 0.4646\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4602\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4153 - val_loss: 0.4548\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4649\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4473\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4401\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4381\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4432\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4356\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.4411\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4308\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4286\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3801 - val_loss: 0.4263\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4246\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4205\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.4233\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.4207\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.4206\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4189\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.4156\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4152\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.4157\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4114\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4127\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4096\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4086\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4076\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.4070\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4058\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.4107\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4060\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4046\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.4053\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.4034\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4048\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4029\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4000\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4010\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4001\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4003\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3989\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.4052\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3965\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3983\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3391 - val_loss: 0.3982\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3986\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3991\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3911\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3945\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3359 - val_loss: 0.3952\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3990\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.3928\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3886\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3337 - val_loss: 0.3943\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3332 - val_loss: 0.3900\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3326 - val_loss: 0.3958\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3319 - val_loss: 0.3902\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3881\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3892\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.3899\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3306 - val_loss: 0.3851\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3298 - val_loss: 0.3910\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3296 - val_loss: 0.3958\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.3928\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3908\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3272 - val_loss: 0.3851\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3837\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3261 - val_loss: 0.3863\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3817\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3873\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3870\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3821\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3247 - val_loss: 0.3829\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3958\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3246 - val_loss: 0.3866\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.3844\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3808\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3236 - val_loss: 0.3776\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3829\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3857\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3800\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3838\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3803\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3843\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3750\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3211 - val_loss: 0.3835\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3801\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3536\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1863 - val_loss: 1.1786\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0403 - val_loss: 0.8401\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7685 - val_loss: 0.7308\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6939 - val_loss: 0.6787\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6522 - val_loss: 0.6478\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6185 - val_loss: 0.6159\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5898 - val_loss: 0.5934\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5661 - val_loss: 0.5775\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5440 - val_loss: 0.5563\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5396\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5071 - val_loss: 0.5268\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4934 - val_loss: 0.5131\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4824 - val_loss: 0.5110\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4723 - val_loss: 0.4977\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4639 - val_loss: 0.4921\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4597 - val_loss: 0.4839\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.4859\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 0.4709\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4692\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4334 - val_loss: 0.4679\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.4609\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4597\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4539\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4527\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4518\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4446\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4480\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4424\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4391\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4348\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 0.4409\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4306\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.4306\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4291\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.4300\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4318\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4277\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4221\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3737 - val_loss: 0.4182\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.4174\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4185\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.4144\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4209\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4124\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4131\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4105\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4063\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4072\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4042\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4039\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4040\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.4024\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.4017\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3517 - val_loss: 0.4034\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4049\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.4135\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4223\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4051\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4042\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4015\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.3983\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.3980\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3989\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3434 - val_loss: 0.3974\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3936\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.3986\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3429 - val_loss: 0.3944\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3918\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3397 - val_loss: 0.3920\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.3949\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3972\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3890\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3942\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.3922\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.3879\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3895\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.4102\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.4031\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.3859\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.3967\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3996\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3332 - val_loss: 0.3877\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3912\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3865\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3822\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3906\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3921\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3841\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3839\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3790\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.3864\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3820\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3775\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3781\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.3930\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3783\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3796\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3828\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3805\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3782\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3379\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.3581 - val_loss: 0.6991\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6920 - val_loss: 0.6391\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6266 - val_loss: 0.6029\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5854 - val_loss: 0.5709\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5528 - val_loss: 0.5535\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.5377\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5126 - val_loss: 0.5215\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.5151\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4818 - val_loss: 0.4990\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4711 - val_loss: 0.4949\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4590 - val_loss: 0.4851\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4542 - val_loss: 0.4796\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4420 - val_loss: 0.4713\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4345 - val_loss: 0.4694\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.4627\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4215 - val_loss: 0.4547\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4510\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4116 - val_loss: 0.4445\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4472\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4029 - val_loss: 0.4396\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4358\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4336\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4373\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4297\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4259\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4261\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4274\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.4249\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3778 - val_loss: 0.4308\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.4203\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.4319\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.4163\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.4207\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.4154\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4139\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.4545\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4196\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4131\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.4085\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4088\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4082\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4040\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4059\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4011\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4025\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4053\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4001\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.3983\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4010\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3965\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3928\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3890\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3451 - val_loss: 0.3937\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.3913\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.3936\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3864\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3882\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3844\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3392 - val_loss: 0.3965\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3831\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3850\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3363 - val_loss: 0.3830\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3862\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3833\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3807\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3774\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3769\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3765\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3723\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3731\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3778\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3720\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3766\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3732\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3724\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3709\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3712\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3716\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3709\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3224 - val_loss: 0.3699\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3714\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3705\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.3675\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3708\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3218 - val_loss: 0.3691\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3710\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3664\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3648\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3638\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3639\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3184 - val_loss: 0.3741\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3181 - val_loss: 0.3677\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3170 - val_loss: 0.3624\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3171 - val_loss: 0.3604\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3160 - val_loss: 0.3664\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3618\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3589\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3771\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3603\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3136 - val_loss: 0.3672\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3117\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6588 - val_loss: 0.5630\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4799 - val_loss: 1.7216\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5981 - val_loss: 0.4519\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.4569\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4279\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3920\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3446 - val_loss: 0.4929\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3758\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3319 - val_loss: 0.3859\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3792\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3752\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3698\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3128 - val_loss: 0.3857\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3677\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3605\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.3579\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.3467\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2981 - val_loss: 0.3667\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.3441\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2946 - val_loss: 0.3547\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3692\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2893 - val_loss: 0.3375\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2844 - val_loss: 0.3461\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.3534\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2826 - val_loss: 0.3458\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.3357\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2793 - val_loss: 0.3308\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2759 - val_loss: 0.3541\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2788 - val_loss: 0.3441\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2756 - val_loss: 0.3282\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2769 - val_loss: 0.3352\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.3251\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2722 - val_loss: 0.3514\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2714 - val_loss: 0.3415\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.3399\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2712 - val_loss: 0.3514\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2692 - val_loss: 0.3523\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2669 - val_loss: 0.3849\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2647 - val_loss: 0.3329\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2641 - val_loss: 0.3375\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.3173\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2615 - val_loss: 0.3244\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2598 - val_loss: 0.3559\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.3263\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2608 - val_loss: 0.3651\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2568 - val_loss: 0.3270\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2577 - val_loss: 0.3398\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.3329\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.3342\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2554 - val_loss: 0.3145\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2557 - val_loss: 0.3352\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2557 - val_loss: 0.3389\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2551 - val_loss: 0.3299\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2528 - val_loss: 0.3384\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2537 - val_loss: 0.4174\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2526 - val_loss: 0.3403\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2495 - val_loss: 0.3355\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2513 - val_loss: 0.3155\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2466 - val_loss: 0.3374\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2480 - val_loss: 0.3493\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.2931\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9940 - val_loss: 0.8402\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6758 - val_loss: 2.6337\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5982 - val_loss: 26.0501\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9229 - val_loss: 0.6780\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4783 - val_loss: 0.4276\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.3921\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4123\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3805\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3791\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3679\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3158 - val_loss: 0.3627\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3551\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3060 - val_loss: 0.3684\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3591\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2990 - val_loss: 0.3494\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2969 - val_loss: 0.3697\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2967 - val_loss: 0.3420\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.3571\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.3436\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.3402\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.3558\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.3391\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2825 - val_loss: 0.3525\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2786 - val_loss: 0.3609\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2784 - val_loss: 0.3628\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2771 - val_loss: 0.3448\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2765 - val_loss: 0.3355\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2749 - val_loss: 0.3439\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2727 - val_loss: 0.3501\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2710 - val_loss: 0.3238\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2712 - val_loss: 0.3343\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.3365\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2672 - val_loss: 0.3254\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2689 - val_loss: 0.3446\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2661 - val_loss: 0.3276\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2640 - val_loss: 0.3643\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2640 - val_loss: 0.3375\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2638 - val_loss: 0.3769\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2631 - val_loss: 0.3379\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.3470\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3083\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4311 - val_loss: 2.6233\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: nan - val_loss: nan\n",
            "121/121 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9300 - val_loss: 0.5764\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4755 - val_loss: 0.4603\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4367\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4336\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.4259\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.3967\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.4511\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3856\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3903\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3915\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3828\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.3847\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3911\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3704\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3207 - val_loss: 0.3757\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3174 - val_loss: 0.3751\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3631\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3735\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.3607\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3084 - val_loss: 0.3639\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3069 - val_loss: 0.3774\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3055 - val_loss: 0.3596\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3664\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3002 - val_loss: 0.3640\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2986 - val_loss: 0.3569\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2950 - val_loss: 0.3512\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2937 - val_loss: 0.3451\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.3561\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3516\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.3438\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.3452\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.3466\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2864 - val_loss: 0.3461\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.3513\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2812 - val_loss: 0.3507\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2820 - val_loss: 0.3550\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2813 - val_loss: 0.3572\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2798 - val_loss: 0.3753\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2773 - val_loss: 0.3392\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2755 - val_loss: 0.3464\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2759 - val_loss: 0.3321\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2731 - val_loss: 0.3340\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2727 - val_loss: 0.3616\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2736 - val_loss: 0.3429\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2737 - val_loss: 0.3656\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2698 - val_loss: 0.3363\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2695 - val_loss: 0.3433\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 0.3475\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2685 - val_loss: 0.3449\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2679 - val_loss: 0.3308\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2680 - val_loss: 0.3442\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2718 - val_loss: 0.3443\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2719 - val_loss: 0.3461\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2653 - val_loss: 0.3461\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2656 - val_loss: 0.4061\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2644 - val_loss: 0.3422\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.3550\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.3317\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2589 - val_loss: 0.3482\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.3583\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3130\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8236 - val_loss: 0.5448\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4837 - val_loss: 0.4714\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4422\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.4383\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4328\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3680 - val_loss: 0.4022\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4169\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.3997\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 0.3976\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.3935\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.3768\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3795\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.4110\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3242 - val_loss: 0.3844\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.3685\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3682\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3127 - val_loss: 0.3617\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3670\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.3971\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3172 - val_loss: 0.3760\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3627\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.3542\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3591\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3574\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.3679\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.3469\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2928 - val_loss: 0.3451\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.3459\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.3514\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.3390\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.3348\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.3366\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2829 - val_loss: 0.3321\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.3489\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2799 - val_loss: 0.3424\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.3631\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.3578\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.3925\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.3583\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.3584\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2815 - val_loss: 0.3479\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2784 - val_loss: 0.3315\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2743 - val_loss: 0.3635\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2723 - val_loss: 0.3247\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.3819\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3448\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2720 - val_loss: 0.3414\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2703 - val_loss: 0.3450\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.3297\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2653 - val_loss: 0.3266\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2668 - val_loss: 0.3227\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2657 - val_loss: 0.3226\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2652 - val_loss: 0.3399\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2646 - val_loss: 0.4528\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2649 - val_loss: 0.3638\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2629 - val_loss: 0.3377\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.3563\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.3366\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2610 - val_loss: 0.3783\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2630 - val_loss: 0.3514\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.3678\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.3566\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3045\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8858 - val_loss: 0.5242\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4940 - val_loss: 0.4735\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4539 - val_loss: 0.4543\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4232 - val_loss: 0.4363\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4617\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4098\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3773 - val_loss: 0.4024\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.3998\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.3958\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.3861\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.3863\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.3768\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.3777\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3871\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.3614\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3790\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3267 - val_loss: 0.3551\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3616\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3542\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3566\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3501\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3460\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3115 - val_loss: 0.3412\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3534\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3062 - val_loss: 0.3632\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3054 - val_loss: 0.3421\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3039 - val_loss: 0.3579\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3464\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2974 - val_loss: 0.3429\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2977 - val_loss: 0.3366\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.3386\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2905 - val_loss: 0.3380\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.3550\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2921 - val_loss: 0.3513\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2922 - val_loss: 0.3387\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2889 - val_loss: 0.3696\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.3598\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2901 - val_loss: 0.3644\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.3494\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2872 - val_loss: 0.3459\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3013\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 5.2197 - val_loss: 4.0665\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.3647 - val_loss: 2.6614\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2911 - val_loss: 1.8534\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6631 - val_loss: 1.3851\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2919 - val_loss: 1.1111\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0696 - val_loss: 0.9499\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9345 - val_loss: 0.8532\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8506 - val_loss: 0.7948\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7974 - val_loss: 0.7584\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7625 - val_loss: 0.7351\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7386 - val_loss: 0.7192\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7214 - val_loss: 0.7079\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7082 - val_loss: 0.6991\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6976 - val_loss: 0.6919\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6887 - val_loss: 0.6856\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6809 - val_loss: 0.6799\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6738 - val_loss: 0.6746\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6672 - val_loss: 0.6695\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6611 - val_loss: 0.6645\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6554 - val_loss: 0.6598\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6498 - val_loss: 0.6552\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6446 - val_loss: 0.6508\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6395 - val_loss: 0.6464\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6347 - val_loss: 0.6423\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6300 - val_loss: 0.6382\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6256 - val_loss: 0.6342\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6212 - val_loss: 0.6305\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6171 - val_loss: 0.6268\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6131 - val_loss: 0.6233\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6093 - val_loss: 0.6198\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6056 - val_loss: 0.6166\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6021 - val_loss: 0.6134\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5986 - val_loss: 0.6103\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5953 - val_loss: 0.6074\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5922 - val_loss: 0.6045\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5892 - val_loss: 0.6019\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5862 - val_loss: 0.5992\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5834 - val_loss: 0.5967\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5807 - val_loss: 0.5943\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5781 - val_loss: 0.5920\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5755 - val_loss: 0.5897\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5731 - val_loss: 0.5875\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5708 - val_loss: 0.5854\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5685 - val_loss: 0.5834\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5664 - val_loss: 0.5815\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5643 - val_loss: 0.5797\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5623 - val_loss: 0.5779\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5603 - val_loss: 0.5763\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5585 - val_loss: 0.5746\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5567 - val_loss: 0.5730\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5550 - val_loss: 0.5715\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5533 - val_loss: 0.5701\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5517 - val_loss: 0.5686\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5502 - val_loss: 0.5672\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5487 - val_loss: 0.5660\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5473 - val_loss: 0.5648\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5459 - val_loss: 0.5635\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5446 - val_loss: 0.5623\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5433 - val_loss: 0.5612\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5421 - val_loss: 0.5602\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5409 - val_loss: 0.5591\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5398 - val_loss: 0.5582\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5387 - val_loss: 0.5572\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5376 - val_loss: 0.5561\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5553\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5356 - val_loss: 0.5544\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5347 - val_loss: 0.5536\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5338 - val_loss: 0.5529\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5329 - val_loss: 0.5521\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.5513\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5313 - val_loss: 0.5507\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.5500\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5494\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5290 - val_loss: 0.5487\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.5481\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5475\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5469\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5264 - val_loss: 0.5464\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5258 - val_loss: 0.5460\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5454\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5247 - val_loss: 0.5450\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5241 - val_loss: 0.5445\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5236 - val_loss: 0.5440\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5232 - val_loss: 0.5436\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5227 - val_loss: 0.5432\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5222 - val_loss: 0.5428\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.5424\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5214 - val_loss: 0.5421\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5209 - val_loss: 0.5417\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5205 - val_loss: 0.5414\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5202 - val_loss: 0.5412\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5408\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5194 - val_loss: 0.5405\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5191 - val_loss: 0.5402\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5188 - val_loss: 0.5399\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5185 - val_loss: 0.5396\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5182 - val_loss: 0.5393\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5179 - val_loss: 0.5391\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5389\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5173 - val_loss: 0.5386\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5508\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 5.0263 - val_loss: 3.8145\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.1800 - val_loss: 2.5158\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1742 - val_loss: 1.7822\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5983 - val_loss: 1.3531\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2561 - val_loss: 1.0952\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0469 - val_loss: 0.9381\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9166 - val_loss: 0.8404\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8338 - val_loss: 0.7786\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7795 - val_loss: 0.7388\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7431 - val_loss: 0.7125\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7178 - val_loss: 0.6943\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6992 - val_loss: 0.6814\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6852 - val_loss: 0.6715\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6739 - val_loss: 0.6637\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6646 - val_loss: 0.6571\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6566 - val_loss: 0.6514\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6495 - val_loss: 0.6461\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6429 - val_loss: 0.6415\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6371 - val_loss: 0.6370\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6315 - val_loss: 0.6329\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6263 - val_loss: 0.6289\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6214 - val_loss: 0.6252\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6168 - val_loss: 0.6216\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6124 - val_loss: 0.6181\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6082 - val_loss: 0.6148\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6042 - val_loss: 0.6116\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6005 - val_loss: 0.6085\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5968 - val_loss: 0.6055\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5933 - val_loss: 0.6027\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5901 - val_loss: 0.5999\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5869 - val_loss: 0.5972\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5839 - val_loss: 0.5947\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5810 - val_loss: 0.5923\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5782 - val_loss: 0.5899\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5756 - val_loss: 0.5877\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5731 - val_loss: 0.5855\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5707 - val_loss: 0.5835\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5684 - val_loss: 0.5815\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5662 - val_loss: 0.5796\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5640 - val_loss: 0.5778\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5620 - val_loss: 0.5760\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5601 - val_loss: 0.5743\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5583 - val_loss: 0.5727\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.5711\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5548 - val_loss: 0.5697\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5532 - val_loss: 0.5683\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5516 - val_loss: 0.5669\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5502 - val_loss: 0.5655\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5487 - val_loss: 0.5641\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5474 - val_loss: 0.5628\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5461 - val_loss: 0.5616\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5448 - val_loss: 0.5607\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5437 - val_loss: 0.5596\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5425 - val_loss: 0.5585\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5414 - val_loss: 0.5575\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5404 - val_loss: 0.5567\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5393 - val_loss: 0.5556\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5384 - val_loss: 0.5547\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5375 - val_loss: 0.5540\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5531\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5358 - val_loss: 0.5522\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5350 - val_loss: 0.5514\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5508\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5335 - val_loss: 0.5500\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5328 - val_loss: 0.5493\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.5487\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5315 - val_loss: 0.5481\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5476\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5303 - val_loss: 0.5470\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.5466\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.5460\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5286 - val_loss: 0.5454\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.5452\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5277 - val_loss: 0.5446\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.5440\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5268 - val_loss: 0.5435\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5264 - val_loss: 0.5434\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5430\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5425\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5252 - val_loss: 0.5421\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5418\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5245 - val_loss: 0.5417\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5242 - val_loss: 0.5414\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5238 - val_loss: 0.5408\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5236 - val_loss: 0.5405\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5233 - val_loss: 0.5402\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5231 - val_loss: 0.5399\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 0.5399\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.5393\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5223 - val_loss: 0.5391\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5220 - val_loss: 0.5389\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.5385\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.5384\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5214 - val_loss: 0.5383\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.5382\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 0.5381\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5208 - val_loss: 0.5376\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5207 - val_loss: 0.5376\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5206 - val_loss: 0.5375\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5202 - val_loss: 0.5369\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5379\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 5.8019 - val_loss: 4.1128\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.5810 - val_loss: 2.6299\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.3580 - val_loss: 1.7975\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6563 - val_loss: 1.3141\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2411 - val_loss: 1.0269\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9893 - val_loss: 0.8535\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8344 - val_loss: 0.7479\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7378 - val_loss: 0.6831\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6766 - val_loss: 0.6424\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6375 - val_loss: 0.6172\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6121 - val_loss: 0.6013\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5955 - val_loss: 0.5909\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5844 - val_loss: 0.5843\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5767 - val_loss: 0.5797\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5714 - val_loss: 0.5762\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5677 - val_loss: 0.5741\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5649 - val_loss: 0.5724\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5627 - val_loss: 0.5707\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5611 - val_loss: 0.5700\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5596 - val_loss: 0.5694\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5584 - val_loss: 0.5681\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5574 - val_loss: 0.5673\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5564 - val_loss: 0.5666\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5555 - val_loss: 0.5655\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5548 - val_loss: 0.5650\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5540 - val_loss: 0.5638\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5534 - val_loss: 0.5634\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5527 - val_loss: 0.5627\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5520 - val_loss: 0.5617\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5513 - val_loss: 0.5607\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5508 - val_loss: 0.5601\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5503 - val_loss: 0.5595\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5497 - val_loss: 0.5590\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5492 - val_loss: 0.5585\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5487 - val_loss: 0.5581\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5481 - val_loss: 0.5580\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5477 - val_loss: 0.5575\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5472 - val_loss: 0.5572\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5468 - val_loss: 0.5568\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5462 - val_loss: 0.5557\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5459 - val_loss: 0.5552\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5454 - val_loss: 0.5545\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5451 - val_loss: 0.5542\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5447 - val_loss: 0.5535\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5444 - val_loss: 0.5533\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5442 - val_loss: 0.5534\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5436 - val_loss: 0.5525\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5432 - val_loss: 0.5518\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5429 - val_loss: 0.5512\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5426 - val_loss: 0.5508\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5422 - val_loss: 0.5502\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5421 - val_loss: 0.5501\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5418 - val_loss: 0.5499\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.5496\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5411 - val_loss: 0.5491\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5410 - val_loss: 0.5493\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5406 - val_loss: 0.5485\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5405 - val_loss: 0.5483\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5401 - val_loss: 0.5485\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5398 - val_loss: 0.5477\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.5471\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5395 - val_loss: 0.5468\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5394 - val_loss: 0.5467\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5391 - val_loss: 0.5466\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 0.5464\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5388 - val_loss: 0.5464\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5384 - val_loss: 0.5459\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5384 - val_loss: 0.5458\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5381 - val_loss: 0.5455\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5380 - val_loss: 0.5456\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5377 - val_loss: 0.5452\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5375 - val_loss: 0.5448\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5375 - val_loss: 0.5449\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5373 - val_loss: 0.5446\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5440\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5436\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5369 - val_loss: 0.5442\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5368 - val_loss: 0.5439\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5436\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.5434\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5364 - val_loss: 0.5433\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5362 - val_loss: 0.5435\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5361 - val_loss: 0.5436\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5359 - val_loss: 0.5429\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5359 - val_loss: 0.5427\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5358 - val_loss: 0.5425\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5357 - val_loss: 0.5423\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5356 - val_loss: 0.5427\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5421\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5354 - val_loss: 0.5421\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5353 - val_loss: 0.5420\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.5416\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5417\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.5419\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5349 - val_loss: 0.5419\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5349 - val_loss: 0.5420\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5347 - val_loss: 0.5413\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5347 - val_loss: 0.5415\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5346 - val_loss: 0.5416\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5408\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5040\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.2785 - val_loss: 0.6402\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5399 - val_loss: 0.5125\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4673 - val_loss: 0.5241\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4484 - val_loss: 0.4884\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.4840\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.4720\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4634\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4543\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4526\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4488\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4470\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.4430\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3898 - val_loss: 0.4411\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4347\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.4299\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4333\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4414\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4311\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3798 - val_loss: 0.4318\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.4241\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4299\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.4234\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.4279\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4245\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4225\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4214\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4205\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.4170\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.4207\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.4210\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4179\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4177\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4144\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4152\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4180\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4199\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4117\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.4119\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4113\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4088\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4108\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4088\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.4168\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4107\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4122\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4112\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4105\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4115\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4078\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4052\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4108\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4042\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4067\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4088\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4158\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4175\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.4070\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4053\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4106\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4098\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4063\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4106\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3803\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0744 - val_loss: 0.9424\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8501 - val_loss: 1.3211\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8301 - val_loss: 0.6235\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5520 - val_loss: 0.5114\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4720 - val_loss: 0.4920\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4589 - val_loss: 0.4786\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4447 - val_loss: 0.4699\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4341 - val_loss: 0.4631\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4587\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.4538\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4466\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4474\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4469\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4483\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4420\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4362\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4440\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4362\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3930 - val_loss: 0.4350\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4311\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4300\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.4296\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.4241\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4273\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3813 - val_loss: 0.4335\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4207\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.4217\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4254\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3781 - val_loss: 0.4199\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.4167\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4235\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.4184\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.4167\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4174\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4136\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4432\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.4156\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4252\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.4128\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4130\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4096\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4108\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3618 - val_loss: 0.4141\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3610 - val_loss: 0.4066\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4123\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4071\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3611 - val_loss: 0.4060\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4113\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3566 - val_loss: 0.4059\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.4046\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4061\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4028\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4021\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.4101\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4086\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4013\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3501 - val_loss: 0.4016\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.4020\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3481 - val_loss: 0.4120\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4005\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3475 - val_loss: 0.4005\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3454 - val_loss: 0.3981\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4070\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4050\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3946\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4041\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3960\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3416 - val_loss: 0.3926\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3936\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.4029\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3398 - val_loss: 0.3989\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3928\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.4031\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.3964\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3923\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3971\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3922\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3357 - val_loss: 0.3910\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.3905\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3955\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.4028\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3978\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3353 - val_loss: 0.3972\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3341 - val_loss: 0.3983\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3330 - val_loss: 0.3905\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.4000\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.4004\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3950\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3934\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3551\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1172 - val_loss: 0.6905\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8300 - val_loss: 0.6238\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5839 - val_loss: 0.5378\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5060 - val_loss: 0.5094\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4797 - val_loss: 0.4962\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4647 - val_loss: 0.4888\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4619 - val_loss: 0.4737\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4477 - val_loss: 0.4665\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4358 - val_loss: 0.4661\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4282 - val_loss: 0.4611\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4239 - val_loss: 0.4526\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4475\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4476\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4475\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4425\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4366\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4362\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4328\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4026 - val_loss: 0.4300\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4293\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4300\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4267\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3968 - val_loss: 0.4254\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.4243\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3948 - val_loss: 0.4247\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4219\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3955 - val_loss: 0.4302\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4256\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4252\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3922 - val_loss: 0.4188\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3919 - val_loss: 0.4346\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4185\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3887 - val_loss: 0.4264\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3895 - val_loss: 0.4190\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3883 - val_loss: 0.4166\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4215\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.4193\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4279\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3861 - val_loss: 0.4182\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3853 - val_loss: 0.4189\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.4230\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4193\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4174\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.4132\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4155\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4139\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.4118\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4106\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3810 - val_loss: 0.4203\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.4137\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.4137\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3799 - val_loss: 0.4116\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4148\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3781 - val_loss: 0.4144\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4116\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4105\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4098\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4127\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4104\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3745 - val_loss: 0.4078\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.4127\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4094\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4171\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4136\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4135\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4087\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3700 - val_loss: 0.4078\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.4054\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4034\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4045\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.4082\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.4037\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.4105\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.4037\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4072\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4034\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4018\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.4049\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.4015\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4029\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4052\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4026\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3999\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4044\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.3998\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.4057\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4004\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.3991\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.3982\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4015\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4050\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4019\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.4103\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3721 - val_loss: 0.4105\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3667 - val_loss: 0.4140\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4058\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3600 - val_loss: 0.4004\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4154\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3573 - val_loss: 0.3979\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3999\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3473\n",
            "Epoch 1/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.7032 - val_loss: 0.5135\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4635 - val_loss: 0.4456\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4308\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.4208\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3666 - val_loss: 0.4028\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3543 - val_loss: 0.3892\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3469 - val_loss: 0.3756\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3384 - val_loss: 0.3850\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3359 - val_loss: 0.3836\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3312 - val_loss: 0.3746\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3260 - val_loss: 0.3798\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3174 - val_loss: 0.3796\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3175 - val_loss: 0.3603\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3129 - val_loss: 0.3521\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3090 - val_loss: 0.3452\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3069 - val_loss: 0.3567\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3055 - val_loss: 0.3658\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3018 - val_loss: 0.3503\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2996 - val_loss: 0.3584\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2971 - val_loss: 0.3462\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.2944 - val_loss: 0.3388\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2926 - val_loss: 0.3568\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2905 - val_loss: 0.3615\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2881 - val_loss: 0.3477\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2885 - val_loss: 0.3417\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2851 - val_loss: 0.3548\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2853 - val_loss: 0.3561\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2843 - val_loss: 0.3463\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2814 - val_loss: 0.3272\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.3330\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2801 - val_loss: 0.3723\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2782 - val_loss: 0.3589\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2765 - val_loss: 0.3401\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2751 - val_loss: 0.4115\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2746 - val_loss: 0.3403\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2725 - val_loss: 0.3444\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2719 - val_loss: 0.3349\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2757 - val_loss: 0.3507\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.2731 - val_loss: 0.3418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7faa44ee23d0>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faa44d8e890>,\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 1...\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCPsox_bzvgW",
        "outputId": "60ad2d5b-31ba-44b1-a1bc-e6f2318b1b43"
      },
      "source": [
        "rnd_search_cv.best_params_\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.009362624718789044, 'n_hidden': 3, 'n_neurons': 65}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrwUwZfR0MoH",
        "outputId": "c6257c51-e91f-45a8-b5d9-6a393aa509b8"
      },
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.30625348289807636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xye4kiTg0Oi5"
      },
      "source": [
        "model = rnd_search_cv.best_estimator_.model"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqEfQ9Dg0R8o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}